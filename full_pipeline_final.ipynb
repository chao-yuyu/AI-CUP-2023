{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline\n",
        "python: 3.8.*\n",
        "\n",
        "use ```Ctrl + ]``` to collapse all section :)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download our starter pack (3~5 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving folder list\n",
            "Retrieving folder 15cJ_K2Tm95UkHgnvvPdMqGQy0_At6lRI checkpoints\n",
            "Retrieving folder 1jIWaLk4VLXEEm7au12mH80bKqFS3-ZKk claim_verification\n",
            "Retrieving folder 1DVfRginiE0thVjKELz7DCsEMYltRaTDG e20_bs32_7e-05_top5\n",
            "Processing file 1AGMfElEghEnYWLYU0YURZrBzmskYuovm val_acc=0.4259_model.750.pt\n",
            "Retrieving folder 19-pRgA1elB6U2UklW6DmUUm9R4qraAu8 sent_retrieval\n",
            "Retrieving folder 15zhuj7t3s5vG4JtFS_PNRTtE5l9mv0nZ e1_bs64_2e-05_neg0.03_top5\n",
            "Processing file 1PBBfgu9lV8_hHdmZRT99bAk_Zl51MZcr model.50.pt\n",
            "Retrieving folder 1r742uPeVnqUm04qUEZpzzpxXZFbj4gNd data\n",
            "Processing file 1hBMys30E2Tw-QCt8FDKKnu-eF_G1tGio dev_doc5sent5.jsonl\n",
            "Processing file 1iHSNpooXDLurizn9sxUbY1Fpk-h9La3i dev_doc5sent5.pkl\n",
            "Processing file 1a0e__D64L8CWhZsvuYZZuXiOZ7a99Bnj hanlp_con_results.pkl\n",
            "Processing file 1BFeoxCm5n0fauW9rbNqy6Se9dK9RnbEJ hanlp_con_test_results.pkl\n",
            "Processing file 1rTvOEQAZG7Hs5aVlTvpnZSW89JWNTUzK public_test.jsonl\n",
            "Processing file 1TbIsMs71WZP2kRpgnn2U383mPavu1G-b public_train.jsonl\n",
            "Processing file 1PDGOk2CCw7LFsATSN02TO8Q3qWIZEnon test_doc5.jsonl\n",
            "Processing file 1xOwH__ssVWnlCbyQfMXgkedqryKluY3x test_doc5sent5.jsonl\n",
            "Processing file 1P6nFa4heHDJFjiEbdN0m7kn_MpzuSEgR test_doc5sent5.pkl\n",
            "Processing file 1y8MJPXUIUxL5siqjS9lB1eQcLAt_5TbE train_doc5.jsonl\n",
            "Processing file 1mQNvv0M0g7aXql9tUQXXI6rMZh0HdRpD train_doc5sent5.jsonl\n",
            "Processing file 1np70uYaVLVqep62qTKL6nC9COXKHze81 train_doc5sent5.pkl\n",
            "Retrieving folder 1kop6Pkva0oORDU9BFpmN_UOiXCLCAe0c wiki-pages\n",
            "Processing file 1sTVRjhZKNQjIR8K88CMJUCSLw4vveLTg wiki-001.jsonl\n",
            "Processing file 1q6K_oCn22WkKk5ajIhzn8KgzYXuFgVSQ wiki-002.jsonl\n",
            "Processing file 1qG0vV8Mx824puUL3Pg_4twiJTvoiXxdk wiki-003.jsonl\n",
            "Processing file 1uyZjqwcj_098mSMgtmak9SLlMZthrk6o wiki-004.jsonl\n",
            "Processing file 1x9OixQWwGivGWsvgZL8dabi4587E3uy9 wiki-005.jsonl\n",
            "Processing file 1OgFP5P7ZztQHeU_xUk21ycNLzoflfJQy wiki-006.jsonl\n",
            "Processing file 1JJwlu2FGm_dyAd28dQjroQmi1fb8_5Sx wiki-007.jsonl\n",
            "Processing file 1sH6X5JheiEkfOwZRq7HPE5U1pueMqsjF wiki-008.jsonl\n",
            "Processing file 1eMguWqUTjo0Q6HYJvT4pf3YLuEdF8aUV wiki-009.jsonl\n",
            "Processing file 1R9HW0GeQXBo5Bi6mcDXXqi_me6ARW3g3 wiki-010.jsonl\n",
            "Processing file 1TlvJf5lP62-a7PCCd7O42JnJso6ppnqN wiki-011.jsonl\n",
            "Processing file 1QDEKOyShPsSGQrGzw8ChJrjrjSBzzmr- wiki-012.jsonl\n",
            "Processing file 1kfREF9TzQXLo2RYhjfYah1EunZopx48r wiki-013.jsonl\n",
            "Processing file 1qmxE66ewfRvKPEdqZ6FzqpWl-jFb_-cU wiki-014.jsonl\n",
            "Processing file 1MRRMRWX7Ig1jB5uMVr-El3CP8eLxY63G wiki-015.jsonl\n",
            "Processing file 1soh98CaH5tyPuLo0QpvUGuy9Nw_0g4c5 wiki-016.jsonl\n",
            "Processing file 1qkTBd7LKsUf97j8LSUKZhlpPfLguQ9dx wiki-017.jsonl\n",
            "Processing file 16LF2Z-WUGJFRe8y851O6_F3_vNOrA2Ky wiki-018.jsonl\n",
            "Processing file 1IU2m8Cm3LPNNlteGNyjeVfFc1orddsch wiki-019.jsonl\n",
            "Processing file 108HqVkaZm4uxehs3R5YJAdr-x3HSLirD wiki-020.jsonl\n",
            "Processing file 14UgYxH3rOg_DSU-ZgIh-AJFqlXAhQYkB wiki-021.jsonl\n",
            "Processing file 1D5E8liujJNzSUsDup8F4Ew2jZrc4domM wiki-022.jsonl\n",
            "Processing file 1EFzRoQvvis8REbL6q1z4K0zGVzO6oFGi wiki-023.jsonl\n",
            "Processing file 15C701SJCcj__2rqbyeNUI6hKjHSPQZT3 wiki-024.jsonl\n",
            "Processing file 15pH4nITCgsGPoQQaqC2ga1xOLO-A_OjB dataset.py\n",
            "Processing file 1NI--USaKNFZOJfWRSCiN-i7twL-2mhFm requirements.txt\n",
            "Processing file 1omVZDMgvWvH15-yegcfNBmJvmBRcG2Rs utils.py\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1AGMfElEghEnYWLYU0YURZrBzmskYuovm\n",
            "From (redirected): https://drive.google.com/uc?id=1AGMfElEghEnYWLYU0YURZrBzmskYuovm&confirm=t&uuid=94edb4a9-fdf3-4724-92ac-dd8dc49b7c56\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/checkpoints/claim_verification/e20_bs32_7e-05_top5/val_acc=0.4259_model.750.pt\n",
            "100%|████████████████████████████████████████| 409M/409M [00:35<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1PBBfgu9lV8_hHdmZRT99bAk_Zl51MZcr\n",
            "From (redirected): https://drive.google.com/uc?id=1PBBfgu9lV8_hHdmZRT99bAk_Zl51MZcr&confirm=t&uuid=c546f5b8-ecf6-4ef2-bfd9-eef3e940563f\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/checkpoints/sent_retrieval/e1_bs64_2e-05_neg0.03_top5/model.50.pt\n",
            "100%|████████████████████████████████████████| 409M/409M [00:35<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hBMys30E2Tw-QCt8FDKKnu-eF_G1tGio\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/dev_doc5sent5.jsonl\n",
            "100%|████████████████████████████████████████| 323k/323k [00:00<00:00, 11.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iHSNpooXDLurizn9sxUbY1Fpk-h9La3i\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/dev_doc5sent5.pkl\n",
            "100%|████████████████████████████████████████| 822k/822k [00:00<00:00, 11.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1a0e__D64L8CWhZsvuYZZuXiOZ7a99Bnj\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/hanlp_con_results.pkl\n",
            "100%|████████████████████████████████████████| 620k/620k [00:00<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BFeoxCm5n0fauW9rbNqy6Se9dK9RnbEJ\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/hanlp_con_test_results.pkl\n",
            "100%|████████████████████████████████████████| 153k/153k [00:00<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rTvOEQAZG7Hs5aVlTvpnZSW89JWNTUzK\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/public_test.jsonl\n",
            "100%|████████████████████████████████████████| 116k/116k [00:00<00:00, 10.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TbIsMs71WZP2kRpgnn2U383mPavu1G-b\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/public_train.jsonl\n",
            "100%|████████████████████████████████████████| 802k/802k [00:00<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PDGOk2CCw7LFsATSN02TO8Q3qWIZEnon\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/test_doc5.jsonl\n",
            "100%|████████████████████████████████████████| 193k/193k [00:00<00:00, 11.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xOwH__ssVWnlCbyQfMXgkedqryKluY3x\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/test_doc5sent5.jsonl\n",
            "100%|████████████████████████████████████████| 318k/318k [00:00<00:00, 11.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1P6nFa4heHDJFjiEbdN0m7kn_MpzuSEgR\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/test_doc5sent5.pkl\n",
            "100%|████████████████████████████████████████| 943k/943k [00:00<00:00, 11.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1y8MJPXUIUxL5siqjS9lB1eQcLAt_5TbE\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/train_doc5.jsonl\n",
            "100%|██████████████████████████████████████| 1.11M/1.11M [00:00<00:00, 11.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mQNvv0M0g7aXql9tUQXXI6rMZh0HdRpD\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/train_doc5sent5.jsonl\n",
            "100%|██████████████████████████████████████| 1.30M/1.30M [00:00<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1np70uYaVLVqep62qTKL6nC9COXKHze81\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/train_doc5sent5.pkl\n",
            "100%|██████████████████████████████████████| 1.58M/1.58M [00:00<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sTVRjhZKNQjIR8K88CMJUCSLw4vveLTg\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-001.jsonl\n",
            "100%|██████████████████████████████████████| 72.2M/72.2M [00:06<00:00, 11.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q6K_oCn22WkKk5ajIhzn8KgzYXuFgVSQ\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-002.jsonl\n",
            "100%|██████████████████████████████████████| 57.5M/57.5M [00:04<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qG0vV8Mx824puUL3Pg_4twiJTvoiXxdk\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-003.jsonl\n",
            "100%|██████████████████████████████████████| 57.6M/57.6M [00:04<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uyZjqwcj_098mSMgtmak9SLlMZthrk6o\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-004.jsonl\n",
            "100%|██████████████████████████████████████| 55.4M/55.4M [00:04<00:00, 11.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x9OixQWwGivGWsvgZL8dabi4587E3uy9\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-005.jsonl\n",
            "100%|██████████████████████████████████████| 45.8M/45.8M [00:03<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OgFP5P7ZztQHeU_xUk21ycNLzoflfJQy\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-006.jsonl\n",
            "100%|██████████████████████████████████████| 47.2M/47.2M [00:04<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JJwlu2FGm_dyAd28dQjroQmi1fb8_5Sx\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-007.jsonl\n",
            "100%|██████████████████████████████████████| 50.2M/50.2M [00:04<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sH6X5JheiEkfOwZRq7HPE5U1pueMqsjF\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-008.jsonl\n",
            "100%|██████████████████████████████████████| 39.1M/39.1M [00:03<00:00, 11.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eMguWqUTjo0Q6HYJvT4pf3YLuEdF8aUV\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-009.jsonl\n",
            "100%|██████████████████████████████████████| 21.8M/21.8M [00:01<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1R9HW0GeQXBo5Bi6mcDXXqi_me6ARW3g3\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-010.jsonl\n",
            "100%|██████████████████████████████████████| 34.2M/34.2M [00:02<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TlvJf5lP62-a7PCCd7O42JnJso6ppnqN\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-011.jsonl\n",
            "100%|██████████████████████████████████████| 27.4M/27.4M [00:02<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QDEKOyShPsSGQrGzw8ChJrjrjSBzzmr-\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-012.jsonl\n",
            "100%|██████████████████████████████████████| 30.0M/30.0M [00:02<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kfREF9TzQXLo2RYhjfYah1EunZopx48r\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-013.jsonl\n",
            "100%|██████████████████████████████████████| 23.3M/23.3M [00:01<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qmxE66ewfRvKPEdqZ6FzqpWl-jFb_-cU\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-014.jsonl\n",
            "100%|██████████████████████████████████████| 39.7M/39.7M [00:03<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MRRMRWX7Ig1jB5uMVr-El3CP8eLxY63G\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-015.jsonl\n",
            "100%|██████████████████████████████████████| 41.8M/41.8M [00:03<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1soh98CaH5tyPuLo0QpvUGuy9Nw_0g4c5\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-016.jsonl\n",
            "100%|██████████████████████████████████████| 42.5M/42.5M [00:03<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qkTBd7LKsUf97j8LSUKZhlpPfLguQ9dx\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-017.jsonl\n",
            "100%|██████████████████████████████████████| 41.1M/41.1M [00:03<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16LF2Z-WUGJFRe8y851O6_F3_vNOrA2Ky\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-018.jsonl\n",
            "100%|██████████████████████████████████████| 40.6M/40.6M [00:03<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IU2m8Cm3LPNNlteGNyjeVfFc1orddsch\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-019.jsonl\n",
            "100%|██████████████████████████████████████| 40.9M/40.9M [00:03<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108HqVkaZm4uxehs3R5YJAdr-x3HSLirD\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-020.jsonl\n",
            "100%|██████████████████████████████████████| 41.5M/41.5M [00:03<00:00, 11.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14UgYxH3rOg_DSU-ZgIh-AJFqlXAhQYkB\n",
            "To: /home/lupin/NCKU-AICUP2023-baseline/baseline/data/wiki-pages/wiki-021.jsonl\n",
            "100%|██████████████████████████████████████| 40.4M/40.4M [00:03<00:00, 11.7MB/s]\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1D5E8liujJNzSUsDup8F4Ew2jZrc4domM \n",
            "\n",
            "Download ended unsuccessfully\n"
          ]
        }
      ],
      "source": [
        "!gdown --folder 1T6jpOtdf_i6XNYA6F_lqU4mRRh1xYPcl\n",
        "!mv baseline/* ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install -r requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h7MSEcenjVrL"
      },
      "source": [
        "notebook1\n",
        "## PART 1. Document retrieval"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare the environment and import all library we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "niqu9pLajYC_"
      },
      "outputs": [],
      "source": [
        "# built-in libs\n",
        "import json\n",
        "import pickle\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Set, Tuple, Union\n",
        "from tqdm import tqdm\n",
        "# 3rd party libs\n",
        "import hanlp\n",
        "import opencc\n",
        "import pandas as pd\n",
        "import wikipedia\n",
        "from hanlp.components.pipeline import Pipeline\n",
        "from pandarallel import pandarallel\n",
        "from transformers import AutoTokenizer,AutoModel\n",
        "import torch\n",
        "# our own libs\n",
        "from utils import (\n",
        "    generate_evidence_to_wiki_pages_mapping,\n",
        "    jsonl_dir_to_df,\n",
        "    load_json,\n",
        "    load_model,\n",
        "    save_checkpoint,\n",
        "    set_lr_scheduler,\n",
        ")\n",
        "from torch.multiprocessing import Pool, Process, set_start_method\n",
        "\n",
        "pandarallel.initialize(progress_bar=True, verbose=0, nb_workers=5)\n",
        "wikipedia.set_lang(\"zh\")\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data, Model setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TRAIN_DATA = load_json(\"data/public_train_all.jsonl\")\n",
        "TEST_DATA = load_json(\"data/private/public_private_combine_test_data.jsonl\")\n",
        "CONVERTER_T2S = opencc.OpenCC(\"t2s.json\")\n",
        "CONVERTER_S2T = opencc.OpenCC(\"s2t.json\")\n",
        "\n",
        "simcse_model=AutoModel.from_pretrained(\"IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese\")\n",
        "simcse_tok=AutoTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese\")\n",
        "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "simcse_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading and concatenating jsonl files in data/wiki-pages\n",
            "Generate parse mapping\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b0467bf692348f7a11b5812f0162e9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=39592), Label(value='0 / 39592')))…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transform to id to evidence_map mapping\n"
          ]
        }
      ],
      "source": [
        "wiki_pages = jsonl_dir_to_df(\"data/wiki-pages\")\n",
        "mapping = generate_evidence_to_wiki_pages_mapping(wiki_pages)\n",
        "del wiki_pages"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data class for type hinting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Claim:\n",
        "    data: str\n",
        "\n",
        "@dataclass\n",
        "class AnnotationID:\n",
        "    id: int\n",
        "\n",
        "@dataclass\n",
        "class EvidenceID:\n",
        "    id: int\n",
        "\n",
        "@dataclass\n",
        "class PageTitle:\n",
        "    title: str\n",
        "\n",
        "@dataclass\n",
        "class SentenceID:\n",
        "    id: int\n",
        "\n",
        "@dataclass\n",
        "class Evidence:\n",
        "    data: List[List[Tuple[AnnotationID, EvidenceID, PageTitle, SentenceID]]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper function"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of consistency, we convert traditional to simplified Chinese first before converting it back to traditional Chinese.  This is due to some errors occuring when converting traditional to traditional Chinese."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A3NU01DnjKp-"
      },
      "outputs": [],
      "source": [
        "def do_st_corrections(text: str) -> str:\n",
        "    simplified = CONVERTER_T2S.convert(text)\n",
        "\n",
        "    return CONVERTER_S2T.convert(simplified)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use constituency parsing to separate part of speeches or so called constituent to extract noun phrases.  In the later stages, we will use the noun phrases as the query to search for relevant documents.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_nps_hanlp(\n",
        "    predictor: Pipeline,\n",
        "    d: Dict[str, Union[int, Claim, Evidence]],\n",
        ") -> List[str]:\n",
        "    claim = d[\"claim\"]\n",
        "    tree = predictor(CONVERTER_T2S.convert(claim))[\"con\"]\n",
        "    nps = [\n",
        "        do_st_corrections(\"\".join(subtree.leaves()))\n",
        "        for subtree in tree.subtrees(lambda t: (\"NP\" in t.label() or \"obj\" in t.label() or \"IP\" in t.label()))\n",
        "    ]\n",
        "\n",
        "    return nps"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Precision refers to how many related documents are retrieved.  Recall refers to how many relevant documents are retrieved.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_precision(\n",
        "    data: List[Dict[str, Union[int, Claim, Evidence]]],\n",
        "    predictions: pd.Series,\n",
        ") -> None:\n",
        "    precision = 0\n",
        "    count = 0\n",
        "\n",
        "    for i, d in enumerate(data):\n",
        "        if d[\"label\"] == \"NOT ENOUGH INFO\":\n",
        "            continue\n",
        "\n",
        "        # Extract all ground truth of titles of the wikipedia pages\n",
        "        # evidence[2] refers to the title of the wikipedia page\n",
        "        gt_pages = set([\n",
        "            evidence[2]\n",
        "            for evidence_set in d[\"evidence\"]\n",
        "            for evidence in evidence_set\n",
        "        ])\n",
        "\n",
        "        predicted_pages = set(predictions.iloc[i][:10])\n",
        "        hits = predicted_pages.intersection(gt_pages)\n",
        "        # print(predicted_pages,hits)\n",
        "        if len(predicted_pages) != 0:\n",
        "            precision += len(hits) / len(predicted_pages)\n",
        "            # precision += len(hits) / 5\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    print(f\"Precision: {precision / count}\")\n",
        "\n",
        "\n",
        "def calculate_recall(\n",
        "    data: List[Dict[str, Union[int, Claim, Evidence]]],\n",
        "    predictions: pd.Series,\n",
        ") -> None:\n",
        "    recall = 0\n",
        "    count = 0\n",
        "\n",
        "    for i, d in enumerate(data):\n",
        "        if d[\"label\"] == \"NOT ENOUGH INFO\":\n",
        "            continue\n",
        "\n",
        "        gt_pages = set([\n",
        "            evidence[2]\n",
        "            for evidence_set in d[\"evidence\"]\n",
        "            for evidence in evidence_set\n",
        "        ])\n",
        "        predicted_pages = set(predictions.iloc[i][:10])\n",
        "\n",
        "        hits = predicted_pages.intersection(gt_pages)\n",
        "\n",
        "        recall += len(hits) / len(gt_pages)\n",
        "        count += 1\n",
        "  \n",
        "    print(f\"Recall: {recall / count}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The default amount of documents retrieved is at most five documents.  This `num_pred_doc` can be adjusted based on your objective.  Save data in jsonl format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_doc(\n",
        "    data: List[Dict[str, Union[int, Claim, Evidence]]],\n",
        "    predictions: pd.Series,\n",
        "    mode: str = \"train\",\n",
        "    num_pred_doc: int = 5,\n",
        ") -> None:\n",
        "    with open(\n",
        "        f\"data/{mode}_doc{num_pred_doc}.jsonl\",\n",
        "        \"w\",\n",
        "        encoding=\"utf8\",\n",
        "    ) as f:\n",
        "        for i, d in enumerate(data):\n",
        "            d[\"predicted_pages\"] = list(predictions.iloc[i])\n",
        "            f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main function for document retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ayGI44qkk_wy"
      },
      "outputs": [],
      "source": [
        "def get_pred_pages(series_data):\n",
        "    nps = series_data[\"hanlp_results\"]\n",
        "\n",
        "\n",
        "    wiki_search_results = [\n",
        "        do_st_corrections(j) for w in nps for j in wikipedia.search(w)\n",
        "    ]\n",
        "    wiki_search_results = list(set(wiki_search_results))\n",
        "    tmp_wiki_search_results=[]\n",
        "    sentence=[]\n",
        "    for page in wiki_search_results:\n",
        "        try:\n",
        "            context = mapping[page.replace(\" \",\"_\").replace(\"-\", \"\")].values()\n",
        "            tt=[]\n",
        "            for setn in context:\n",
        "                if \"|\" not in setn or \"=\" not in setn :\n",
        "                    tt.append(setn)\n",
        "            sentence.append(\" \".join(tt))\n",
        "            tmp_wiki_search_results.append(page)\n",
        "        except:\n",
        "            continue\n",
        "    wiki_search_results = tmp_wiki_search_results\n",
        "    return [wiki_search_results,sentence]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1. Get noun phrases from hanlp consituency parsing tree"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup [HanLP](https://github.com/hankcs/HanLP) predictor (1 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building model \u001b[5m\u001b[33m...\u001b[0m\u001b[0m"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m predictor \u001b[39m=\u001b[39m (hanlp\u001b[39m.\u001b[39mpipeline()\u001b[39m.\u001b[39mappend(\n\u001b[0;32m----> 2\u001b[0m     hanlp\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mMSR_TOK_ELECTRA_BASE_CRF\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      3\u001b[0m     output_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtok\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\u001b[39m.\u001b[39mappend(\n\u001b[1;32m      5\u001b[0m     hanlp\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mCTB9_CON_FULL_TAG_ERNIE_GRAM\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     output_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcon\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     input_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtok\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m ))\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/hanlp/__init__.py:43\u001b[0m, in \u001b[0;36mload\u001b[0;34m(save_dir, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mhanlp_common\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m HANLP_VERBOSE\n\u001b[1;32m     42\u001b[0m     verbose \u001b[39m=\u001b[39m HANLP_VERBOSE\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m load_from_meta_file(save_dir, \u001b[39m'\u001b[39;49m\u001b[39mmeta.json\u001b[39;49m\u001b[39m'\u001b[39;49m, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/hanlp/utils/component_util.py:106\u001b[0m, in \u001b[0;36mload_from_meta_file\u001b[0;34m(save_dir, meta_filename, transform_only, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_dir, \u001b[39m'\u001b[39m\u001b[39mconfig.json\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m--> 106\u001b[0m         obj\u001b[39m.\u001b[39;49mload(save_dir, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    107\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m         obj\u001b[39m.\u001b[39mload(metapath, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/hanlp/common/torch_component.py:178\u001b[0m, in \u001b[0;36mTorchComponent.load\u001b[0;34m(self, save_dir, devices, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     flash(\u001b[39m'\u001b[39m\u001b[39mBuilding model [blink][yellow]...[/yellow][/blink]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# Some legacy versions accidentally put training into config file\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_model(\n\u001b[1;32m    179\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmerge_dict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, save_dir\u001b[39m=\u001b[39;49msave_dir)\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    181\u001b[0m     flash(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/hanlp/components/taggers/transformers/transformer_tagger.py:147\u001b[0m, in \u001b[0;36mTransformerTagger.build_model\u001b[0;34m(self, training, extra_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_model\u001b[39m(\u001b[39mself\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extra_embeddings: Embedding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule:\n\u001b[1;32m    146\u001b[0m     model \u001b[39m=\u001b[39m TransformerTaggingModel(\n\u001b[0;32m--> 147\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_transformer(training\u001b[39m=\u001b[39;49mtraining),\n\u001b[1;32m    148\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabs\u001b[39m.\u001b[39mtag),\n\u001b[1;32m    149\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcrf,\n\u001b[1;32m    150\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39msecondary_encoder\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    151\u001b[0m         extra_embeddings\u001b[39m=\u001b[39mextra_embeddings\u001b[39m.\u001b[39mmodule(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabs) \u001b[39mif\u001b[39;00m extra_embeddings \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    153\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/hanlp/components/classifiers/transformer_classifier.py:118\u001b[0m, in \u001b[0;36mTransformerComponent.build_transformer\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_transformer\u001b[39m(\u001b[39mself\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 118\u001b[0m     transformer \u001b[39m=\u001b[39m TransformerEncoder(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mtransformer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_tokenizer,\n\u001b[1;32m    119\u001b[0m                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49maverage_subwords,\n\u001b[1;32m    120\u001b[0m                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mscalar_mix, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mword_dropout,\n\u001b[1;32m    121\u001b[0m                                      ret_raw_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mret_raw_hidden_states,\n\u001b[1;32m    122\u001b[0m                                      training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m    123\u001b[0m     transformer_layers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtransformer_layers\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m transformer_layers:\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/hanlp/layers/transformers/encoder.py:72\u001b[0m, in \u001b[0;36mTransformerEncoder.__init__\u001b[0;34m(self, transformer, transformer_tokenizer, average_subwords, scalar_mix, word_dropout, max_sequence_length, ret_raw_hidden_states, transformer_args, trainable, training)\u001b[0m\n\u001b[1;32m     70\u001b[0m     transformer_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     71\u001b[0m transformer_args[\u001b[39m'\u001b[39m\u001b[39moutput_hidden_states\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m output_hidden_states\n\u001b[0;32m---> 72\u001b[0m transformer \u001b[39m=\u001b[39m AutoModel_\u001b[39m.\u001b[39;49mfrom_pretrained(transformer, training\u001b[39m=\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m trainable,\n\u001b[1;32m     73\u001b[0m                                          \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtransformer_args)\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m max_sequence_length \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     max_sequence_length \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_position_embeddings\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/hanlp/layers/transformers/pt_imports.py:25\u001b[0m, in \u001b[0;36mAutoModel_.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, training, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pretrained_model_name_or_path, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     24\u001b[0m     pretrained_model_name_or_path \u001b[39m=\u001b[39m get_tokenizer_mirror(pretrained_model_name_or_path)\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfrom_config(AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m     26\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:411\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    410\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 411\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49m_from_config(config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    413\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    414\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/modeling_utils.py:1096\u001b[0m, in \u001b[0;36mPreTrainedModel._from_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1095\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1098\u001b[0m \u001b[39m# restore default dtype if it was modified\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py:824\u001b[0m, in \u001b[0;36mElectraModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m config\n\u001b[1;32m    823\u001b[0m \u001b[39m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[0;32m--> 824\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpost_init()\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/modeling_utils.py:1062\u001b[0m, in \u001b[0;36mPreTrainedModel.post_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost_init\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1058\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[39m    A method executed at the end of each Transformer model initialization, to execute code that needs the model's\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[39m    modules properly initialized (such as weight initialization).\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_weights()\n\u001b[1;32m   1063\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_compatibility_gradient_checkpointing()\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/modeling_utils.py:1553\u001b[0m, in \u001b[0;36mPreTrainedModel.init_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprune_heads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpruned_heads)\n\u001b[1;32m   1551\u001b[0m \u001b[39mif\u001b[39;00m _init_weights:\n\u001b[1;32m   1552\u001b[0m     \u001b[39m# Initialize weights\u001b[39;00m\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_weights)\n\u001b[1;32m   1555\u001b[0m     \u001b[39m# Tie weights should be skipped when not initializing all weights\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m     \u001b[39m# since from_pretrained(...) calls tie weights anyways\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtie_weights()\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:728\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    725\u001b[0m \n\u001b[1;32m    726\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 728\u001b[0m     module\u001b[39m.\u001b[39;49mapply(fn)\n\u001b[1;32m    729\u001b[0m fn(\u001b[39mself\u001b[39m)\n\u001b[1;32m    730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:728\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    725\u001b[0m \n\u001b[1;32m    726\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 728\u001b[0m     module\u001b[39m.\u001b[39;49mapply(fn)\n\u001b[1;32m    729\u001b[0m fn(\u001b[39mself\u001b[39m)\n\u001b[1;32m    730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "    \u001b[0;31m[... skipping similar frames: Module.apply at line 728 (2 times)]\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:728\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    725\u001b[0m \n\u001b[1;32m    726\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 728\u001b[0m     module\u001b[39m.\u001b[39;49mapply(fn)\n\u001b[1;32m    729\u001b[0m fn(\u001b[39mself\u001b[39m)\n\u001b[1;32m    730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:729\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m    728\u001b[0m     module\u001b[39m.\u001b[39mapply(fn)\n\u001b[0;32m--> 729\u001b[0m fn(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/modeling_utils.py:1214\u001b[0m, in \u001b[0;36mPreTrainedModel._initialize_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, \u001b[39m\"\u001b[39m\u001b[39m_is_hf_initialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1213\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 1214\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_weights(module)\n\u001b[1;32m   1215\u001b[0m module\u001b[39m.\u001b[39m_is_hf_initialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/electra/modeling_electra.py:684\u001b[0m, in \u001b[0;36mElectraPreTrainedModel._init_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initialize the weights\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(module, nn\u001b[39m.\u001b[39mLinear):\n\u001b[1;32m    682\u001b[0m     \u001b[39m# Slightly different from the TF version which uses truncated_normal for initialization\u001b[39;00m\n\u001b[1;32m    683\u001b[0m     \u001b[39m# cf https://github.com/pytorch/pytorch/pull/5617\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m     module\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mnormal_(mean\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, std\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49minitializer_range)\n\u001b[1;32m    685\u001b[0m     \u001b[39mif\u001b[39;00m module\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m         module\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mzero_()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "predictor = (hanlp.pipeline().append(\n",
        "    hanlp.load(\"MSR_TOK_ELECTRA_BASE_CRF\"),\n",
        "    output_key=\"tok\",\n",
        ").append(\n",
        "    hanlp.load(\"CTB9_CON_FULL_TAG_ERNIE_GRAM\"),\n",
        "    output_key=\"con\",\n",
        "    input_key=\"tok\",\n",
        "))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will skip this process which for creating parsing tree when demo on class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hanlp_file = f\"data/hanlp_con_results.pkl\"\n",
        "if Path(hanlp_file).exists():\n",
        "    with open(hanlp_file, \"rb\") as f:\n",
        "        hanlp_results = pickle.load(f)\n",
        "else:\n",
        "    hanlp_results = [get_nps_hanlp(predictor, d) for d in TRAIN_DATA]\n",
        "    with open(hanlp_file, \"wb\") as f:\n",
        "        pickle.dump(hanlp_results, f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get pages via wiki online api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_path = f\"data/train_doc5_all_page_other_predictor.jsonl\"\n",
        "if Path(doc_path).exists():\n",
        "    train_df = pd.DataFrame(load_json(doc_path))\n",
        "else:\n",
        "    train_df = pd.DataFrame(TRAIN_DATA)\n",
        "    train_df.loc[:, \"hanlp_results\"] = hanlp_results\n",
        "    result = train_df.parallel_apply(get_pred_pages, axis=1)\n",
        "    predicted_results=[]\n",
        "    predicted_sentence=[]\n",
        "    for elmt in result:\n",
        "        predicted_results.append(elmt[0])\n",
        "        predicted_sentence.append(elmt[1])\n",
        "    train_df.loc[:,\"all_page\"]=predicted_results\n",
        "    train_df.loc[:,\"all_sentences\"]=predicted_sentence\n",
        "    train_df[[\"id\",\"label\", \"claim\",\"evidence\",\"hanlp_results\", \"all_page\",\"all_sentences\"]].to_json(\n",
        "        \"data/train_doc5_all_page_other_predictor.jsonl\",\n",
        "        orient=\"records\",\n",
        "        lines=True,\n",
        "        force_ascii=False,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3038it [45:57,  1.10it/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 1; 10.91 GiB total capacity; 5.83 GiB already allocated; 18.06 MiB free; 8.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m combine_pad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(combine_pad)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m combine_attention_mask \u001b[39m=\u001b[39m (combine_pad\u001b[39m!=\u001b[39msimcse_tok\u001b[39m.\u001b[39mpad_token_id)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 71\u001b[0m combine_output \u001b[39m=\u001b[39m simcse_model(\n\u001b[1;32m     72\u001b[0m     input_ids \u001b[39m=\u001b[39;49m combine_pad,\n\u001b[1;32m     73\u001b[0m     attention_mask \u001b[39m=\u001b[39;49m combine_attention_mask\n\u001b[1;32m     74\u001b[0m )\u001b[39m.\u001b[39mpooler_output\n\u001b[1;32m     75\u001b[0m score \u001b[39m=\u001b[39m cos(claim_output,combine_output)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m i,t \u001b[39min\u001b[39;00m  \u001b[39menumerate\u001b[39m(branch_2_term_label):\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    611\u001b[0m         hidden_states,\n\u001b[1;32m    612\u001b[0m         attention_mask,\n\u001b[1;32m    613\u001b[0m         layer_head_mask,\n\u001b[1;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    616\u001b[0m         past_key_value,\n\u001b[1;32m    617\u001b[0m         output_attentions,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    493\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    496\u001b[0m         hidden_states,\n\u001b[1;32m    497\u001b[0m         attention_mask,\n\u001b[1;32m    498\u001b[0m         head_mask,\n\u001b[1;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    500\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    504\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    416\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    424\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 425\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    426\u001b[0m         hidden_states,\n\u001b[1;32m    427\u001b[0m         attention_mask,\n\u001b[1;32m    428\u001b[0m         head_mask,\n\u001b[1;32m    429\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    430\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    431\u001b[0m         past_key_value,\n\u001b[1;32m    432\u001b[0m         output_attentions,\n\u001b[1;32m    433\u001b[0m     )\n\u001b[1;32m    434\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    435\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/Contest/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:347\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    344\u001b[0m         relative_position_scores_key \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbhrd,lrd->bhlr\u001b[39m\u001b[39m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[1;32m    345\u001b[0m         attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m relative_position_scores_query \u001b[39m+\u001b[39m relative_position_scores_key\n\u001b[0;32m--> 347\u001b[0m attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m/\u001b[39;49m math\u001b[39m.\u001b[39;49msqrt(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention_head_size)\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m attention_mask\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 1; 10.91 GiB total capacity; 5.83 GiB already allocated; 18.06 MiB free; 8.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=1)\n",
        "simcse_model.eval()\n",
        "results=[]\n",
        "batch=16\n",
        "for i, elmt in tqdm(train_df.iterrows()):\n",
        "    page_score={}\n",
        "    tmp=[]\n",
        "    for title in elmt['all_page']:\n",
        "        if title in elmt[\"claim\"] or title.replace('·',\"\") in elmt[\"claim\"]:\n",
        "            tmp.append(title)\n",
        "    claim_input=simcse_tok(CONVERTER_T2S.convert(elmt[\"claim\"]),return_tensors=\"pt\").to(device)\n",
        "    claim_output = simcse_model(**claim_input).pooler_output\n",
        "    for i in range(0,len(elmt['all_page']),batch):\n",
        "\n",
        "        branch_1_term_label=[]\n",
        "        branch_1_term=[]\n",
        "        branch_1_sentence=[]\n",
        "\n",
        "        branch_2_term_label=[]\n",
        "        branch_2_term_sentence=[]\n",
        "        for term,sentence in zip(elmt['all_page'][i:i+batch],elmt['all_sentences'][i:i+batch]):\n",
        "            if term in tmp:\n",
        "                branch_1_term_label.append(term)\n",
        "                branch_1_term.append(simcse_tok(CONVERTER_T2S.convert(term),max_length=256,truncation=True)[\"input_ids\"])\n",
        "                branch_1_sentence.append(simcse_tok(CONVERTER_T2S.convert(sentence),max_length=256,truncation=True)[\"input_ids\"])\n",
        "            else:\n",
        "                branch_2_term_label.append(term)\n",
        "                branch_2_term_sentence.append(simcse_tok(CONVERTER_T2S.convert(term+\" : \"+sentence),max_length=256,truncation=True)[\"input_ids\"])\n",
        "        if branch_1_term_label!=[]:\n",
        "            term_max_len= max(map(len,branch_1_term))\n",
        "            sentences_max_len= max(map(len,branch_1_sentence))\n",
        "            term_pad=[]\n",
        "            sentence_pad=[]\n",
        "            for i in range(len(branch_1_term)):\n",
        "                if len(branch_1_term[i])<term_max_len:\n",
        "                    term_pad.append(branch_1_term[i]+[simcse_tok.pad_token_id]*(term_max_len-len(branch_1_term[i])))\n",
        "                else:\n",
        "                    term_pad.append(branch_1_term[i])\n",
        "\n",
        "                if len(branch_1_sentence[i])<sentences_max_len:\n",
        "                    sentence_pad.append(branch_1_sentence[i]+[simcse_tok.pad_token_id]*(sentences_max_len-len(branch_1_sentence[i])))\n",
        "                else:\n",
        "                    sentence_pad.append(branch_1_sentence[i])\n",
        "            term_pad = torch.tensor(term_pad).to(device)\n",
        "            term_attention_mask = (term_pad!=simcse_tok.pad_token_id).to(device)\n",
        "\n",
        "            sentence_pad = torch.tensor(sentence_pad).to(device)\n",
        "            sen_attention_mask = (sentence_pad!=simcse_tok.pad_token_id).to(device)\n",
        "            term_output = simcse_model(\n",
        "                input_ids = term_pad,\n",
        "                attention_mask = term_attention_mask\n",
        "            ).pooler_output\n",
        "            sen_output = simcse_model(\n",
        "                input_ids = sentence_pad,\n",
        "                attention_mask = sen_attention_mask\n",
        "            ).pooler_output\n",
        "            score = ((cos(claim_output,term_output)+cos(claim_output,sen_output)*1.3)/2).tolist()\n",
        "            for i,t in enumerate(branch_1_term_label):\n",
        "                page_score[t]=score[i]\n",
        "\n",
        "        if branch_2_term_label!=[]:\n",
        "            combine_pad=[]\n",
        "            combine_max_len= max(map(len,branch_2_term_sentence))\n",
        "            for i in range(len(branch_2_term_sentence)):\n",
        "                if len(branch_2_term_sentence[i])<combine_max_len:\n",
        "                    combine_pad.append(branch_2_term_sentence[i]+[simcse_tok.pad_token_id]*(combine_max_len-len(branch_2_term_sentence[i])))\n",
        "                else:\n",
        "                    combine_pad.append(branch_2_term_sentence[i])\n",
        "            combine_pad = torch.tensor(combine_pad).to(device)\n",
        "            combine_attention_mask = (combine_pad!=simcse_tok.pad_token_id).to(device)\n",
        "            combine_output = simcse_model(\n",
        "                input_ids = combine_pad,\n",
        "                attention_mask = combine_attention_mask\n",
        "            ).pooler_output\n",
        "            score = cos(claim_output,combine_output).tolist()\n",
        "            for i,t in  enumerate(branch_2_term_label):\n",
        "                page_score[t]=score[i]\n",
        "\n",
        "    results.append([key.replace(\" \",\"_\").replace(\"-\", \"\") for key,_ in sorted(page_score.items(), key=lambda item: item[1],reverse=True)[:10]])\n",
        "    # break    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results[236]\n",
        "train_df_t = pd.DataFrame(TRAIN_DATA)\n",
        "train_df_t[\"predicted_pages\"]=results\n",
        "train_df_t[[\"id\",\"label\", \"claim\",\"evidence\", \"predicted_pages\"]].to_json(\n",
        "    \"data/train_doc10_all_method.jsonl\",\n",
        "    orient=\"records\",\n",
        "    lines=True,\n",
        "    force_ascii=False,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2. Calculate our results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>claim</th>\n",
              "      <th>evidence</th>\n",
              "      <th>predicted_pages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2663</td>\n",
              "      <td>refutes</td>\n",
              "      <td>天衛三軌道在天王星內部的磁層，以《 仲夏夜之夢 》作者緹坦妮雅命名。</td>\n",
              "      <td>[[[4209, 4331, 天衛三, 2]]]</td>\n",
              "      <td>[天衛三, 天王星, 磁層, 天衛二十三, 天衛四, 冥衛三, 軌道, 緹坦妮雅, 天衛二,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2399</td>\n",
              "      <td>refutes</td>\n",
              "      <td>信天翁科的活動範圍位於北冰洋以及南太平洋，牠的翼展可達到3.7米，是世界上現存的翼展最大的鳥類。</td>\n",
              "      <td>[[[2719, 2928, 信天翁科, 2]]]</td>\n",
              "      <td>[漂泊信天翁, 北冰洋, 翼展, 信天翁科, 鳥, 大鰹鳥屬, 太平洋, 南太平洋, 牠, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8075</td>\n",
              "      <td>NOT ENOUGH INFO</td>\n",
              "      <td>F.I.R. 的 團員有主唱Faye飛 （ 詹雯婷 ） 、 吉他手Real阿沁 （ 黃漢青 ...</td>\n",
              "      <td>[[7208, None, None, None]]</td>\n",
              "      <td>[F.I.R.飛兒樂團, 樂團, 主唱, 飛_(消歧義), SpeXial, 阿沁, 閃靈樂...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8931</td>\n",
              "      <td>NOT ENOUGH INFO</td>\n",
              "      <td>香港國際機場全年24小時運作，它從2001年起一直躋身世界最佳機場 ， 並8度獲評級爲全宇宙...</td>\n",
              "      <td>[[8162, None, None, None]]</td>\n",
              "      <td>[香港國際機場, 香港航空業, 香港之最, 啓德機場, 國泰貨運, 香港國際機場旅客捷運系統...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>332</td>\n",
              "      <td>NOT ENOUGH INFO</td>\n",
              "      <td>北理工是歷史上最後一批副部級高校，黨委書記和校長列入中央管理的高校 ， 簡稱中管高校 ， 俗...</td>\n",
              "      <td>[[204, None, None, None]]</td>\n",
              "      <td>[黨委書記和校長列入中央管理的高校, 中央部屬高校, 北京航空航天大學, 中央軍事委員會訓練...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id            label                                              claim  \\\n",
              "0  2663          refutes                 天衛三軌道在天王星內部的磁層，以《 仲夏夜之夢 》作者緹坦妮雅命名。   \n",
              "1  2399          refutes   信天翁科的活動範圍位於北冰洋以及南太平洋，牠的翼展可達到3.7米，是世界上現存的翼展最大的鳥類。   \n",
              "2  8075  NOT ENOUGH INFO  F.I.R. 的 團員有主唱Faye飛 （ 詹雯婷 ） 、 吉他手Real阿沁 （ 黃漢青 ...   \n",
              "3  8931  NOT ENOUGH INFO  香港國際機場全年24小時運作，它從2001年起一直躋身世界最佳機場 ， 並8度獲評級爲全宇宙...   \n",
              "4   332  NOT ENOUGH INFO  北理工是歷史上最後一批副部級高校，黨委書記和校長列入中央管理的高校 ， 簡稱中管高校 ， 俗...   \n",
              "\n",
              "                     evidence  \\\n",
              "0    [[[4209, 4331, 天衛三, 2]]]   \n",
              "1   [[[2719, 2928, 信天翁科, 2]]]   \n",
              "2  [[7208, None, None, None]]   \n",
              "3  [[8162, None, None, None]]   \n",
              "4   [[204, None, None, None]]   \n",
              "\n",
              "                                     predicted_pages  \n",
              "0  [天衛三, 天王星, 磁層, 天衛二十三, 天衛四, 冥衛三, 軌道, 緹坦妮雅, 天衛二,...  \n",
              "1  [漂泊信天翁, 北冰洋, 翼展, 信天翁科, 鳥, 大鰹鳥屬, 太平洋, 南太平洋, 牠, ...  \n",
              "2  [F.I.R.飛兒樂團, 樂團, 主唱, 飛_(消歧義), SpeXial, 阿沁, 閃靈樂...  \n",
              "3  [香港國際機場, 香港航空業, 香港之最, 啓德機場, 國泰貨運, 香港國際機場旅客捷運系統...  \n",
              "4  [黨委書記和校長列入中央管理的高校, 中央部屬高校, 北京航空航天大學, 中央軍事委員會訓練...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df_t = pd.DataFrame(load_json('data/train_doc10_all_method.jsonl'))\n",
        "train_df_t.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.10352898811668668\n",
            "Recall: 0.9305945664786142\n"
          ]
        }
      ],
      "source": [
        "calculate_precision(TRAIN_DATA, train_df_t['predicted_pages'])\n",
        "calculate_recall(TRAIN_DATA, train_df_t['predicted_pages'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3. Repeat the same process on test set\n",
        "Create parsing tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_DATA = load_json(\"data/private/public_private_combine_test_data.jsonl\")\n",
        "hanlp_test_file = f\"data/hanlp_con_combine_test_results_imp.pkl\"\n",
        "if Path(hanlp_test_file).exists():\n",
        "    with open(hanlp_test_file, \"rb\") as f:\n",
        "        hanlp_results = pickle.load(f)\n",
        "else:\n",
        "    hanlp_results = [get_nps_hanlp(predictor, d) for d in TEST_DATA]\n",
        "    with open(hanlp_test_file, \"wb\") as f:\n",
        "        pickle.dump(hanlp_results, f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get pages via wiki online api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aa444f436f944d9911b86730aced5a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=302), Label(value='0 / 302'))), HB…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_doc_path = f\"data/combine_test_doc5_all_page_with_sentences.jsonl\"\n",
        "if Path(test_doc_path).exists():\n",
        "    test_df = pd.DataFrame(load_json(test_doc_path))\n",
        "else:\n",
        "    test_df = pd.DataFrame(TEST_DATA)\n",
        "    test_df.loc[:, \"hanlp_results\"] = hanlp_results\n",
        "    test_results = test_df.parallel_apply(get_pred_pages, axis=1)\n",
        "    predicted_results=[]\n",
        "    predicted_sentence=[]\n",
        "    for elmt in test_results:\n",
        "        predicted_results.append(elmt[0])\n",
        "        predicted_sentence.append(elmt[1])\n",
        "    test_df.loc[:,\"all_page\"]=predicted_results\n",
        "    test_df.loc[:,\"all_sentences\"]=predicted_sentence\n",
        "    test_df[[\"id\", \"claim\",\"hanlp_results\", \"all_page\",\"all_sentences\"]].to_json(\n",
        "        \"data/combine_test_doc5_all_page_with_sentences.jsonl\",\n",
        "        orient=\"records\",\n",
        "        lines=True,\n",
        "        force_ascii=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4090it [1:05:21,  1.04it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 82\u001b[0m\n\u001b[1;32m     77\u001b[0m combine_attention_mask \u001b[39m=\u001b[39m (combine_pad\u001b[39m!=\u001b[39msimcse_tok\u001b[39m.\u001b[39mpad_token_id)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m combine_output \u001b[39m=\u001b[39m simcse_model(\n\u001b[1;32m     79\u001b[0m     input_ids \u001b[39m=\u001b[39m combine_pad,\n\u001b[1;32m     80\u001b[0m     attention_mask \u001b[39m=\u001b[39m combine_attention_mask\n\u001b[1;32m     81\u001b[0m )\u001b[39m.\u001b[39mpooler_output\n\u001b[0;32m---> 82\u001b[0m score \u001b[39m=\u001b[39m cos(claim_output,combine_output)\u001b[39m.\u001b[39;49mtolist()\n\u001b[1;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m i,t \u001b[39min\u001b[39;00m  \u001b[39menumerate\u001b[39m(branch_2_term_label):\n\u001b[1;32m     84\u001b[0m     page_score[t]\u001b[39m=\u001b[39mscore[i]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=1)\n",
        "simcse_model.eval()\n",
        "results=[]\n",
        "batch=16\n",
        "for i, elmt in tqdm(test_df.iterrows()):\n",
        "\n",
        "    page_score={}\n",
        "    tmp=[]\n",
        "    for title in elmt['all_page']:\n",
        "        if title in elmt[\"claim\"] or title.replace('·',\"\") in elmt[\"claim\"]:\n",
        "            tmp.append(title)\n",
        "    claim_input=simcse_tok(CONVERTER_T2S.convert(elmt[\"claim\"]),return_tensors=\"pt\").to(\"cuda:0\")\n",
        "    claim_output = simcse_model(**claim_input).pooler_output\n",
        "    for i in range(0,len(elmt['all_page']),batch):\n",
        "\n",
        "        branch_1_term_label=[]\n",
        "        branch_1_term=[]\n",
        "        branch_1_sentence=[]\n",
        "\n",
        "        branch_2_term_label=[]\n",
        "        branch_2_term_sentence=[]\n",
        "        for term,sentence in zip(elmt['all_page'][i:i+batch],elmt['all_sentences'][i:i+batch]):\n",
        "            if term in tmp:\n",
        "                branch_1_term_label.append(term)\n",
        "                branch_1_term.append(simcse_tok(CONVERTER_T2S.convert(term),max_length=256,truncation=True)[\"input_ids\"])\n",
        "                branch_1_sentence.append(simcse_tok(CONVERTER_T2S.convert(sentence),max_length=256,truncation=True)[\"input_ids\"])\n",
        "            else:\n",
        "                branch_2_term_label.append(term)\n",
        "                branch_2_term_sentence.append(simcse_tok(CONVERTER_T2S.convert(term+\" : \"+sentence),max_length=256,truncation=True)[\"input_ids\"])\n",
        "        if branch_1_term_label!=[]:\n",
        "            term_max_len= max(map(len,branch_1_term))\n",
        "            sentences_max_len= max(map(len,branch_1_sentence))\n",
        "            term_pad=[]\n",
        "            sentence_pad=[]\n",
        "            for i in range(len(branch_1_term)):\n",
        "                if len(branch_1_term[i])<term_max_len:\n",
        "                    term_pad.append(branch_1_term[i]+[simcse_tok.pad_token_id]*(term_max_len-len(branch_1_term[i])))\n",
        "                else:\n",
        "                    term_pad.append(branch_1_term[i])\n",
        "\n",
        "                if len(branch_1_sentence[i])<sentences_max_len:\n",
        "                    sentence_pad.append(branch_1_sentence[i]+[simcse_tok.pad_token_id]*(sentences_max_len-len(branch_1_sentence[i])))\n",
        "                else:\n",
        "                    sentence_pad.append(branch_1_sentence[i])\n",
        "            term_pad = torch.tensor(term_pad).to(\"cuda:0\")\n",
        "            term_attention_mask = (term_pad!=simcse_tok.pad_token_id).to(\"cuda:0\")\n",
        "\n",
        "            sentence_pad = torch.tensor(sentence_pad).to(\"cuda:0\")\n",
        "            sen_attention_mask = (sentence_pad!=simcse_tok.pad_token_id).to(\"cuda:0\")\n",
        "            term_output = simcse_model(\n",
        "                input_ids = term_pad,\n",
        "                attention_mask = term_attention_mask\n",
        "            ).pooler_output\n",
        "            sen_output = simcse_model(\n",
        "                input_ids = sentence_pad,\n",
        "                attention_mask = sen_attention_mask\n",
        "            ).pooler_output\n",
        "            score = ((cos(claim_output,term_output)+cos(claim_output,sen_output)*1.3)/2).tolist()\n",
        "            for i,t in enumerate(branch_1_term_label):\n",
        "                page_score[t]=score[i]\n",
        "        if branch_2_term_label!=[]:\n",
        "            combine_pad=[]\n",
        "            combine_max_len= max(map(len,branch_2_term_sentence))\n",
        "            for i in range(len(branch_2_term_sentence)):\n",
        "                if len(branch_2_term_sentence[i])<combine_max_len:\n",
        "                    combine_pad.append(branch_2_term_sentence[i]+[simcse_tok.pad_token_id]*(combine_max_len-len(branch_2_term_sentence[i])))\n",
        "                else:\n",
        "                    combine_pad.append(branch_2_term_sentence[i])\n",
        "            combine_pad = torch.tensor(combine_pad).to(\"cuda:0\")\n",
        "            combine_attention_mask = (combine_pad!=simcse_tok.pad_token_id).to(\"cuda:0\")\n",
        "            combine_output = simcse_model(\n",
        "                input_ids = combine_pad,\n",
        "                attention_mask = combine_attention_mask\n",
        "            ).pooler_output\n",
        "            score = cos(claim_output,combine_output).tolist()\n",
        "            for i,t in  enumerate(branch_2_term_label):\n",
        "                page_score[t]=score[i]\n",
        "    \n",
        "    results.append([key.replace(\" \",\"_\").replace(\"-\", \"\") for key,val in sorted(page_score.items(), key=lambda item: item[1],reverse=True)[:10]])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_DATA = load_json(\"data/private/public_private_combine_test_data.jsonl\")\n",
        "test_df_t = pd.DataFrame(TEST_DATA)\n",
        "test_df_t.loc[:, \"predicted_pages\"] = results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df_t[[\"id\", \"claim\",\"predicted_pages\"]].to_json(\n",
        "    \"data/combine_test_doc10.jsonl\",\n",
        "    orient=\"records\",\n",
        "    lines=True,\n",
        "    force_ascii=False,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol4zFkSbjgXF"
      },
      "source": [
        "notebook2\n",
        "## PART 2. Sentence retrieval"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import some libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlliDsgXjisj"
      },
      "outputs": [],
      "source": [
        "# built-in libs\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Set, Tuple, Union\n",
        "from dataclasses import dataclass\n",
        "# third-party libs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandarallel import pandarallel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers import (\n",
        "    #AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_scheduler,\n",
        ")\n",
        "from modeling_bert import BertForSequenceClassification\n",
        "from dataset import BERTDataset, Dataset\n",
        "\n",
        "# local libs\n",
        "from utils import (\n",
        "    generate_evidence_to_wiki_pages_mapping,\n",
        "    jsonl_dir_to_df,\n",
        "    load_json,\n",
        "    load_model,\n",
        "    save_checkpoint,\n",
        "    set_lr_scheduler,\n",
        ")\n",
        "\n",
        "pandarallel.initialize(progress_bar=True, verbose=0, nb_workers=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Claim:\n",
        "    data: str\n",
        "\n",
        "@dataclass\n",
        "class AnnotationID:\n",
        "    id: int\n",
        "\n",
        "@dataclass\n",
        "class EvidenceID:\n",
        "    id: int\n",
        "\n",
        "@dataclass\n",
        "class PageTitle:\n",
        "    title: str\n",
        "\n",
        "@dataclass\n",
        "class SentenceID:\n",
        "    id: int\n",
        "\n",
        "@dataclass\n",
        "class Evidence:\n",
        "    data: List[List[Tuple[AnnotationID, EvidenceID, PageTitle, SentenceID]]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Global variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J3BBLE3_hlPi"
      },
      "outputs": [],
      "source": [
        "SEED = 40\n",
        "\n",
        "TRAIN_DATA = load_json(\"data/public_train_all.jsonl\")\n",
        "TEST_DATA = load_json(\"data/public_test.jsonl\")\n",
        "DOC_DATA = load_json(\"data/train_doc10_all_method.jsonl\")\n",
        "\n",
        "LABEL2ID: Dict[str, int] = {\n",
        "    \"supports\": 0,\n",
        "    \"refutes\": 1,\n",
        "    \"NOT ENOUGH INFO\": 2,\n",
        "}\n",
        "ID2LABEL: Dict[int, str] = {v: k for k, v in LABEL2ID.items()}\n",
        "\n",
        "_y = [LABEL2ID[data[\"label\"]] for data in TRAIN_DATA]\n",
        "# GT means Ground Truth\n",
        "TRAIN_GT, DEV_GT = train_test_split(\n",
        "    DOC_DATA,\n",
        "    shuffle=True,\n",
        "    test_size=0.2,\n",
        "    random_state=SEED,\n",
        "    stratify=_y,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preload wiki database (1 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading and concatenating jsonl files in data/wiki-pages\n",
            "Generate parse mapping\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a16d92b632f4498a2be7f04e5689924",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=118776), Label(value='0 / 118776')…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transform to id to evidence_map mapping\n"
          ]
        }
      ],
      "source": [
        "wiki_pages = jsonl_dir_to_df(\"data/wiki-pages\")\n",
        "mapping = generate_evidence_to_wiki_pages_mapping(wiki_pages)\n",
        "del wiki_pages"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper function"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate precision for sentence retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evdi_calculate_precision(\n",
        "    data: List[Dict[str, Union[int, Claim, Evidence]]],\n",
        "    predictions: pd.Series,\n",
        ") -> None:\n",
        "    precision = 0\n",
        "    count = 0\n",
        "\n",
        "    for i, d in enumerate(data):\n",
        "        if d[\"label\"] == \"NOT ENOUGH INFO\":\n",
        "            continue\n",
        "\n",
        "        # Extract all ground truth of titles of the wikipedia pages\n",
        "        # evidence[2] refers to the title of the wikipedia page\n",
        "        gt_pages = set([\n",
        "            (evidence[2],evidence[3])\n",
        "            for evidence_set in d[\"evidence\"]\n",
        "            for evidence in evidence_set\n",
        "        ])\n",
        "\n",
        "        predicted_pages = set([(t[0],t[1]) for id,t in enumerate(predictions.iloc[i][0:2])])\n",
        "\n",
        "        hits = predicted_pages.intersection(gt_pages)\n",
        "\n",
        "        if len(predicted_pages) != 0:\n",
        "            precision += len(hits) / len(predicted_pages)\n",
        "        count += 1\n",
        "\n",
        "    # Macro precision\n",
        "    print(f\"Precision: {precision / count}\")\n",
        "\n",
        "\n",
        "def evdi_calculate_recall(\n",
        "    data: List[Dict[str, Union[int, Claim, Evidence]]],\n",
        "    predictions: pd.Series,\n",
        ") -> None:\n",
        "    recall = 0\n",
        "    count = 0\n",
        "\n",
        "    for i, d in enumerate(data):\n",
        "        if d[\"label\"] == \"NOT ENOUGH INFO\":\n",
        "            continue\n",
        "\n",
        "        gt_pages = set([\n",
        "            (evidence[2],evidence[3])\n",
        "            for evidence_set in d[\"evidence\"]\n",
        "            for evidence in evidence_set\n",
        "        ])\n",
        "        predicted_pages = set([(t[0],t[1]) for id,t in enumerate(predictions.iloc[i][0:2])])\n",
        "\n",
        "        hits = predicted_pages.intersection(gt_pages)\n",
        "\n",
        "        recall += len(hits) / len(gt_pages)\n",
        "        count += 1\n",
        "    print(f\"Recall: {recall / count}\")\n",
        "    return recall / count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evidence_macro_precision(\n",
        "    instance: Dict,\n",
        "    top_rows: pd.DataFrame,\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"Calculate precision for sentence retrieval\n",
        "    This function is modified from fever-scorer.\n",
        "    https://github.com/sheffieldnlp/fever-scorer/blob/master/src/fever/scorer.py\n",
        "\n",
        "    Args:\n",
        "        instance (dict): a row of the dev set (dev.jsonl) of test set (test.jsonl)\n",
        "        top_rows (pd.DataFrame): our predictions with the top probabilities\n",
        "\n",
        "        IMPORTANT!!!\n",
        "        instance (dict) should have the key of `evidence`.\n",
        "        top_rows (pd.DataFrame) should have a column `predicted_evidence`.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float]:\n",
        "        [1]: relevant and retrieved (numerator of precision)\n",
        "        [2]: retrieved (denominator of precision)\n",
        "    \"\"\"\n",
        "    this_precision = 0.0\n",
        "    this_precision_hits = 0.0\n",
        "    # print(top_rows)\n",
        "    # Return 0, 0 if label is not enough info since not enough info does not\n",
        "    # contain any evidence.\n",
        "    if instance[\"label\"].upper() != \"NOT ENOUGH INFO\":\n",
        "        # e[2] is the page title, e[3] is the sentence index\n",
        "        all_evi = [[e[2], e[3]]\n",
        "                   for eg in instance[\"evidence\"]\n",
        "                   for e in eg\n",
        "                   if e[3] is not None]\n",
        "        claim = instance[\"claim\"]\n",
        "        predicted_evidence = top_rows[top_rows[\"claim\"] ==\n",
        "                                      claim][\"predicted_evidence\"].tolist()\n",
        "\n",
        "        for prediction in predicted_evidence:\n",
        "            if prediction in all_evi:\n",
        "                this_precision += 1.0\n",
        "            this_precision_hits += 1.0\n",
        "\n",
        "        return (this_precision /\n",
        "                this_precision_hits) if this_precision_hits > 0 else 1.0, 1.0\n",
        "\n",
        "    return 0.0, 0.0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate recall for sentence retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evidence_macro_recall(\n",
        "    instance: Dict,\n",
        "    top_rows: pd.DataFrame,\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"Calculate recall for sentence retrieval\n",
        "    This function is modified from fever-scorer.\n",
        "    https://github.com/sheffieldnlp/fever-scorer/blob/master/src/fever/scorer.py\n",
        "\n",
        "    Args:\n",
        "        instance (dict): a row of the dev set (dev.jsonl) of test set (test.jsonl)\n",
        "        top_rows (pd.DataFrame): our predictions with the top probabilities\n",
        "\n",
        "        IMPORTANT!!!\n",
        "        instance (dict) should have the key of `evidence`.\n",
        "        top_rows (pd.DataFrame) should have a column `predicted_evidence`.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float]:\n",
        "        [1]: relevant and retrieved (numerator of recall)\n",
        "        [2]: relevant (denominator of recall)\n",
        "    \"\"\"\n",
        "    # We only want to score F1/Precision/Recall of recalled evidence for NEI claims\n",
        "    if instance[\"label\"].upper() != \"NOT ENOUGH INFO\":\n",
        "        # If there's no evidence to predict, return 1\n",
        "        if len(instance[\"evidence\"]) == 0 or all(\n",
        "            [len(eg) == 0 for eg in instance]):\n",
        "            return 1.0, 1.0\n",
        "\n",
        "        claim = instance[\"claim\"]\n",
        "\n",
        "        predicted_evidence = top_rows[top_rows[\"claim\"] ==\n",
        "                                      claim][\"predicted_evidence\"].tolist()\n",
        "\n",
        "        for evidence_group in instance[\"evidence\"]:\n",
        "            evidence = [[e[2], e[3]] for e in evidence_group]\n",
        "            if all([item in predicted_evidence for item in evidence]):\n",
        "                # We only want to score complete groups of evidence. Incomplete\n",
        "                # groups are worthless.\n",
        "                return 1.0, 1.0\n",
        "        return 0.0, 1.0\n",
        "    return 0.0, 0.0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate the scores of sentence retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_retrieval(\n",
        "    probs: np.ndarray,\n",
        "    df_evidences: pd.DataFrame,\n",
        "    ground_truths: pd.DataFrame,\n",
        "    top_n: int = 5,\n",
        "    cal_scores: bool = True,\n",
        "    save_name: str = None,\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"Calculate the scores of sentence retrieval\n",
        "\n",
        "    Args:\n",
        "        probs (np.ndarray): probabilities of the candidate retrieved sentences\n",
        "        df_evidences (pd.DataFrame): the candiate evidence sentences paired with claims\n",
        "        ground_truths (pd.DataFrame): the loaded data of dev.jsonl or test.jsonl\n",
        "        top_n (int, optional): the number of the retrieved sentences. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, float]: F1 score, precision, and recall\n",
        "    \"\"\"\n",
        "    df_evidences[\"prob\"] = probs\n",
        "    top_rows = (\n",
        "        df_evidences.groupby(\"claim\").apply(\n",
        "        lambda x: x.nlargest(top_n, \"prob\"))\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    if cal_scores:\n",
        "        macro_precision = 0\n",
        "        macro_precision_hits = 0\n",
        "        macro_recall = 0\n",
        "        macro_recall_hits = 0\n",
        "\n",
        "        for i, instance in enumerate(ground_truths):\n",
        "            macro_prec = evidence_macro_precision(instance, top_rows)\n",
        "            macro_precision += macro_prec[0]\n",
        "            macro_precision_hits += macro_prec[1]\n",
        "\n",
        "            macro_rec = evidence_macro_recall(instance, top_rows)\n",
        "            macro_recall += macro_rec[0]\n",
        "            macro_recall_hits += macro_rec[1]\n",
        "            # break\n",
        "        pr = (macro_precision /\n",
        "              macro_precision_hits) if macro_precision_hits > 0 else 1.0\n",
        "        rec = (macro_recall /\n",
        "               macro_recall_hits) if macro_recall_hits > 0 else 0.0\n",
        "        f1 = 2.0 * pr * rec / (pr + rec)\n",
        "    import json\n",
        "    if save_name is not None:\n",
        "        # write doc7_sent5 file\n",
        "        with open(f\"data/{save_name}\", \"w\") as f:\n",
        "            for instance in ground_truths:\n",
        "                claim = instance[\"claim\"]\n",
        "                predicted_evidence = top_rows[\n",
        "                    top_rows[\"claim\"] == claim\n",
        "                ][\"predicted_evidence\"].tolist()\n",
        "                \n",
        "                instance[\"predicted_evidence\"] = predicted_evidence\n",
        "                f.write(json.dumps(instance, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    if cal_scores:\n",
        "        return {\"F1 score\": f1, \"Precision\": pr, \"Recall\": rec}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inference script to get probabilites for the candidate evidence sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_predicted_probs(\n",
        "    model: nn.Module,\n",
        "    dataloader: Dataset,\n",
        "    device: torch.device,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Inference script to get probabilites for the candidate evidence sentences\n",
        "\n",
        "    Args:\n",
        "        model: the one from HuggingFace Transformers\n",
        "        dataloader: devset or testset in torch dataloader\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: probabilites of the candidate evidence sentences\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            probs.extend(torch.softmax(logits, dim=1)[:, 1].tolist())\n",
        "            # probs.extend(torch.argmax(torch.softmax(logits, dim=1),dim=1).tolist())\n",
        "            # break\n",
        "    return np.array(probs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AicupTopkEvidenceBERTDataset class for AICUP dataset with top-k evidence sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SentRetrievalBERTDataset(BERTDataset):\n",
        "    \"\"\"AicupTopkEvidenceBERTDataset class for AICUP dataset with top-k evidence sentences.\"\"\"\n",
        "\n",
        "    def __getitem__(\n",
        "        self,\n",
        "        idx: int,\n",
        "        **kwargs,\n",
        "    ) -> Tuple[Dict[str, torch.Tensor], int]:\n",
        "        item = self.data.iloc[idx]\n",
        "        sentA = item[\"claim\"]\n",
        "        sentB = item[\"text\"]\n",
        "        # print(self.tokenizer(sentA))\n",
        "        # print(sentB)\n",
        "        # claim [SEP] text\n",
        "        concat = self.tokenizer(\n",
        "            sentA,\n",
        "            sentB,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "        )\n",
        "        # print(concat.items())\n",
        "        concat_ten = {k: torch.tensor(v) for k, v in concat.items()}\n",
        "        # print(\"label\" in item)\n",
        "        if \"label\" in item:\n",
        "            concat_ten[\"labels\"] = torch.tensor(item[\"label\"])\n",
        "\n",
        "        return concat_ten"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main function for sentence retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gpvXpFwXszfv"
      },
      "outputs": [],
      "source": [
        "def pair_with_wiki_sentences(\n",
        "    mapping: Dict[str, Dict[int, str]],\n",
        "    df: pd.DataFrame,\n",
        "    negative_ratio: float,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Only for creating train sentences.\"\"\"\n",
        "    claims = []\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    # positive\n",
        "    for i in range(len(df)):\n",
        "        # if df[\"label\"].iloc[i] == \"NOT ENOUGH INFO\":\n",
        "        #     continue\n",
        "\n",
        "        claim = df[\"claim\"].iloc[i]\n",
        "        evidence_sets = df[\"evidence\"].iloc[i]\n",
        "        for evidence_set in evidence_sets:\n",
        "            sents = []\n",
        "            for evidence in evidence_set:\n",
        "                # evidence[2] is the page title\n",
        "                # print(evidence)\n",
        "                if not isinstance(evidence, list):\n",
        "                    continue\n",
        "                # print(evidence)\n",
        "                page = evidence[2].replace(\" \", \"_\")\n",
        "                # the only page with weird name\n",
        "                if page == \"臺灣海峽危機#第二次臺灣海峽危機（1958）\":\n",
        "                    continue\n",
        "                # evidence[3] is in form of int however, mapping requires str\n",
        "                sent_idx = str(evidence[3])\n",
        "                if len(evidence_set)!=1:\n",
        "                    claims.append(claim)\n",
        "                    sentences.append(mapping[page][sent_idx])\n",
        "                    labels.append(1)\n",
        "\n",
        "                sents.append(mapping[page][sent_idx])\n",
        "\n",
        "            whole_evidence = \" \".join(sents)\n",
        "\n",
        "            claims.append(claim)\n",
        "            sentences.append(whole_evidence)\n",
        "            labels.append(1)\n",
        "\n",
        "\n",
        "\n",
        "    # negative\n",
        "    for i in range(len(df)):\n",
        "        # if df[\"label\"].iloc[i] == \"NOT ENOUGH INFO\":\n",
        "        #     continue\n",
        "        claim = df[\"claim\"].iloc[i]\n",
        "\n",
        "        evidence_set = set([(evidence[2], str(evidence[3]))\n",
        "                            for evidences in df[\"evidence\"][i]\n",
        "                            for evidence in evidences if isinstance(evidence, list)])\n",
        "        predicted_pages = df[\"predicted_pages\"][i]\n",
        "        # predicted_pages = predicted_pages + evidence_set\n",
        "        for page in predicted_pages:\n",
        "            page = page.replace(\" \", \"_\")\n",
        "            try:\n",
        "                page_sent_id_pairs = [\n",
        "                    (page, sent_idx) for sent_idx in mapping[page].keys()\n",
        "                ]\n",
        "            except KeyError:\n",
        "                # print(f\"{page} is not in our Wiki db.\")\n",
        "                continue\n",
        "\n",
        "            for pair in page_sent_id_pairs:\n",
        "                text = mapping[page][pair[1]]\n",
        "                if pair in evidence_set:\n",
        "                    continue\n",
        "                # `np.random.rand(1) <= 0.05`: Control not to add too many negative samples\n",
        "                if text != \"\" and ('|' not in text or '=' not in text):\n",
        "                    if np.random.rand(1) <= negative_ratio:\n",
        "                        claims.append(claim)\n",
        "                        sentences.append(text)\n",
        "                        labels.append(0)\n",
        "\n",
        "\n",
        "    return pd.DataFrame({\"claim\": claims, \"text\": sentences, \"label\": labels})\n",
        "\n",
        "\n",
        "def pair_with_wiki_sentences_eval(\n",
        "    mapping: Dict[str, Dict[int, str]],\n",
        "    df: pd.DataFrame,\n",
        "    is_testset: bool = False,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Only for creating dev and test sentences.\"\"\"\n",
        "    claims = []\n",
        "    sentences = []\n",
        "    evidence = []\n",
        "    predicted_evidence = []\n",
        "\n",
        "    # negative\n",
        "    for i in range(len(df)):\n",
        "        # if df[\"label\"].iloc[i] == \"NOT ENOUGH INFO\":\n",
        "            # continue\n",
        "        claim = df[\"claim\"].iloc[i]\n",
        "\n",
        "        predicted_pages = df[\"predicted_pages\"][i]\n",
        "        for page in predicted_pages:\n",
        "            page = page.replace(\" \", \"_\")\n",
        "            try:\n",
        "                page_sent_id_pairs = [(page, k) for k in mapping[page]]\n",
        "            except KeyError:\n",
        "                # print(f\"{page} is not in our Wiki db.\")\n",
        "                continue\n",
        "\n",
        "            for page_name, sentence_id in page_sent_id_pairs:\n",
        "                text = mapping[page][sentence_id]\n",
        "                if text != \"\":\n",
        "                    claims.append(claim)\n",
        "                    sentences.append(text)\n",
        "                    if not is_testset:\n",
        "                        evidence.append(df[\"evidence\"].iloc[i])\n",
        "                    predicted_evidence.append([page_name, int(sentence_id)])\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"claim\": claims,\n",
        "        \"text\": sentences,\n",
        "        \"evidence\": evidence if not is_testset else None,\n",
        "        \"predicted_evidence\": predicted_evidence,\n",
        "    })"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1. Setup training environment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title  { display-mode: \"form\" }\n",
        "\n",
        "MODEL_NAME = \"hfl/chinese-bert-wwm-ext\"  #@param {type:\"string\"}\n",
        "NUM_EPOCHS = 10  #@param {type:\"integer\"}\n",
        "LR = 2e-5  #@param {type:\"number\"}\n",
        "TRAIN_BATCH_SIZE = 16  #@param {type:\"integer\"}\n",
        "TEST_BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
        "NEGATIVE_RATIO = 0.085  #@param {type:\"number\"}\n",
        "VALIDATION_STEP = 300  #@param {type:\"integer\"}\n",
        "TOP_N = 5  #@param {type:\"integer\"}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experiment Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ToLvE9oxIXQo"
      },
      "outputs": [],
      "source": [
        "EXP_DIR = f\"sent_retrieval/e{NUM_EPOCHS}_bs{TRAIN_BATCH_SIZE}_\" + f\"{LR}_neg{NEGATIVE_RATIO}_top{TOP_N}_all_ext\"\n",
        "LOG_DIR = \"logs/\" + EXP_DIR\n",
        "CKPT_DIR = \"checkpoints/\" + EXP_DIR\n",
        "\n",
        "if not Path(LOG_DIR).exists():\n",
        "    Path(LOG_DIR).mkdir(parents=True)\n",
        "\n",
        "if not Path(CKPT_DIR).exists():\n",
        "    Path(CKPT_DIR).mkdir(parents=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2. Combine claims and evidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now using the following train data with 0 (Negative) and 1 (Positive)\n",
            "0    45362\n",
            "1    15619\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "train_df = pair_with_wiki_sentences(\n",
        "    mapping,\n",
        "    pd.DataFrame(TRAIN_GT),\n",
        "    NEGATIVE_RATIO,\n",
        ")\n",
        "counts = train_df[\"label\"].value_counts()\n",
        "print(\"Now using the following train data with 0 (Negative) and 1 (Positive)\")\n",
        "print(counts)\n",
        "\n",
        "dev_evidences = pair_with_wiki_sentences_eval(mapping, pd.DataFrame(DEV_GT))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3. Start training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataloader things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l48WifjeIGui"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_dataset = SentRetrievalBERTDataset(train_df, tokenizer=tokenizer)\n",
        "val_dataset = SentRetrievalBERTDataset(dev_evidences, tokenizer=tokenizer)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        ")\n",
        "eval_dataloader = DataLoader(val_dataset, batch_size=TEST_BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save your memory."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4rl_u0YbeQtY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at yechen/bert-large-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at yechen/bert-large-chinese and are newly initialized: ['ext_dense.bias', 'classifier.bias', 'classifier.weight', 'ext_dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.load_state_dict(torch.load(\"checkpoints/sent_retrieval/e10_bs32_2e-05_neg0.085_top5_all_ext/model.1899.pt\"))\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "num_training_steps = NUM_EPOCHS * len(train_dataloader)\n",
        "lr_scheduler = set_lr_scheduler(optimizer, num_training_steps)\n",
        "\n",
        "writer = SummaryWriter(LOG_DIR)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please make sure that you are using gpu when training (5 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1AHGaKh1eKmg"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0583c9c9c6fb4e9981923be5e65f5acb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/38120 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "238c2e2916d6447d90bd718deec3ff92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.4101963121667645, 'Precision': 0.2748650269945951, 'Recall': 0.8080383923215357}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dcf36d9016a42398168d5f15d18d282",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.41383052983595964, 'Precision': 0.2775044991001741, 'Recall': 0.8134373125374925}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e34b188ce7794ce990a8205d4f845ead",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.4067793865298869, 'Precision': 0.27354529094180596, 'Recall': 0.7930413917216557}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ccdbc997c8f4738aef4c242bf76ced4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.4061312905655683, 'Precision': 0.27246550689861454, 'Recall': 0.7972405518896221}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93782b3d8cc446449f4dba5d9ca84bfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.40796349284318956, 'Precision': 0.27390521895620307, 'Recall': 0.7990401919616077}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b361919fa456423d9bf594baded04f33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.40286000902406266, 'Precision': 0.27078584283142804, 'Recall': 0.7864427114577085}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09dcafd3c33c49618a387b42fc99aaf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.38729683040664004, 'Precision': 0.26070785842830896, 'Recall': 0.7528494301139772}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8be87aae503b43cb8d52de429b61a47b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.3983884680702607, 'Precision': 0.2680263947210502, 'Recall': 0.7756448710257948}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a86ff88705349a7bef09ade6c4dea66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.3982023177069879, 'Precision': 0.2677864427114521, 'Recall': 0.7762447510497901}\n",
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcf0811f26b0402a8dd1ddfba0a98a20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.4037980952051185, 'Precision': 0.270785842831428, 'Recall': 0.7936412717456509}\n",
            "Finished training!\n"
          ]
        }
      ],
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "current_steps = 0\n",
        "step_cnt=0\n",
        "max=0\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    \n",
        "    for i,batch in enumerate(train_dataloader):\n",
        "        \n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        # print(batch)\n",
        "        # break\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss/4\n",
        "        loss.backward()\n",
        "        step_cnt+=1\n",
        "        if step_cnt==4 or i==len(train_dataloader)-1:\n",
        "            step_cnt=0\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix(loss=loss.item()*4)\n",
        "        writer.add_scalar(\"training_loss\", loss.item(), current_steps)\n",
        "\n",
        "        y_pred = torch.argmax(outputs.logits, dim=1).tolist()\n",
        "        y_true = batch[\"labels\"].tolist()\n",
        "\n",
        "        current_steps += 1\n",
        "\n",
        "        if i==len(train_dataloader)-1:#\n",
        "            print(\"Start validation\")\n",
        "            probs = get_predicted_probs(model, eval_dataloader, device)\n",
        "\n",
        "            val_results = evaluate_retrieval(\n",
        "                probs=probs,\n",
        "                df_evidences=dev_evidences,\n",
        "                ground_truths=DEV_GT,\n",
        "                top_n=TOP_N,\n",
        "            )\n",
        "            print(val_results)\n",
        "            if val_results['F1 score']>max:\n",
        "                \n",
        "                val_results = evaluate_retrieval(\n",
        "                    probs=probs,\n",
        "                    df_evidences=dev_evidences,\n",
        "                    ground_truths=DEV_GT,\n",
        "                    top_n=TOP_N,\n",
        "                    save_name=f\"dev_doc10sent{TOP_N}_large.jsonl\",\n",
        "                )\n",
        "                max = val_results['F1 score']\n",
        "            # log each metric separately to TensorBoard\n",
        "            for metric_name, metric_value in val_results.items():\n",
        "                writer.add_scalar(\n",
        "                    f\"dev_{metric_name}\",\n",
        "                    metric_value,\n",
        "                    current_steps,\n",
        "                )\n",
        "\n",
        "            save_checkpoint(\n",
        "                model,val_results, CKPT_DIR, current_steps\n",
        "                mark=f\"val_F1={val_results['F1 score']:.4f}\",\n",
        "            )\n",
        "\n",
        "print(\"Finished training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start validation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d20764c19f24bcca43abc38c9237309",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F1 score': 0.40026761344894174, 'Precision': 0.26922615476904066, 'Recall': 0.7798440311937612}\n"
          ]
        }
      ],
      "source": [
        "print(\"Start validation\")\n",
        "probs = get_predicted_probs(model, eval_dataloader, device)\n",
        "\n",
        "val_results = evaluate_retrieval(\n",
        "    probs=probs,\n",
        "    df_evidences=dev_evidences,\n",
        "    ground_truths=DEV_GT,\n",
        "    top_n=TOP_N,\n",
        ")\n",
        "print(val_results)\n",
        "if val_results['F1 score']>max:\n",
        "    \n",
        "    val_results = evaluate_retrieval(\n",
        "        probs=probs,\n",
        "        df_evidences=dev_evidences,\n",
        "        ground_truths=DEV_GT,\n",
        "        top_n=TOP_N,\n",
        "        save_name=f\"dev_doc10sent{TOP_N}_large.jsonl\",\n",
        "    )\n",
        "    max = val_results['F1 score']\n",
        "# log each metric separately to TensorBoard\n",
        "for metric_name, metric_value in val_results.items():\n",
        "    writer.add_scalar(\n",
        "        f\"dev_{metric_name}\",\n",
        "        metric_value,\n",
        "        current_steps,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation part (15 mins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QS1Ei5DAIO5p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start final evaluations and write prediction files.\n",
            "Start calculating training scores\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0861178bea044a799f4c4c7f7f8397f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10173 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training scores => {'F1 score': 0.43625463261664854, 'Precision': 0.29348739495800735, 'Recall': 0.8494897959183674}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9370cbec14842b096ac403de92d7acc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation scores => {'F1 score': 0.42019263533901646, 'Precision': 0.2813437312537435, 'Recall': 0.829634073185363}\n"
          ]
        }
      ],
      "source": [
        "# ckpt_name = \"model.5409.pt\"  #@param {type:\"string\"}\n",
        "# model = load_model(model, ckpt_name, CKPT_DIR)\n",
        "model.load_state_dict(torch.load(\"checkpoints/sent_retrieval/e10_bs32_2e-05_neg0.085_top5_all_ext/model.1899.pt\", map_location=device))\n",
        "\n",
        "print(\"Start final evaluations and write prediction files.\")\n",
        "\n",
        "train_evidences = pair_with_wiki_sentences_eval(\n",
        "    mapping=mapping,\n",
        "    df=pd.DataFrame(TRAIN_GT),\n",
        ")\n",
        "train_set = SentRetrievalBERTDataset(train_evidences, tokenizer)\n",
        "train_dataloader = DataLoader(train_set, batch_size=TEST_BATCH_SIZE)\n",
        "\n",
        "print(\"Start calculating training scores\")\n",
        "probs = get_predicted_probs(model, train_dataloader, device)\n",
        "train_results = evaluate_retrieval(\n",
        "    probs=probs,\n",
        "    df_evidences=train_evidences,\n",
        "    ground_truths=TRAIN_GT,\n",
        "    top_n=TOP_N,\n",
        "    save_name=f\"train_doc10sent{TOP_N}_all_ext.jsonl\",\n",
        ")\n",
        "print(f\"Training scores => {train_results}\")\n",
        "\n",
        "# print(\"Start validation\")\n",
        "probs = get_predicted_probs(model, eval_dataloader, device)\n",
        "val_results = evaluate_retrieval(\n",
        "    probs=probs,\n",
        "    df_evidences=dev_evidences,\n",
        "    ground_truths=DEV_GT,\n",
        "    top_n=TOP_N,\n",
        "    save_name=f\"dev_doc10sent{TOP_N}_all_ext.jsonl\",\n",
        ")\n",
        "\n",
        "print(f\"Validation scores => {val_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5774309723889556\n",
            "Recall: 0.7736191798147838\n"
          ]
        }
      ],
      "source": [
        "top_rows = pd.DataFrame(load_json(\"data/train_doc10sent5_all_ext.jsonl\"))\n",
        "\n",
        "evdi_calculate_precision(TRAIN_GT, top_rows['predicted_evidence'])\n",
        "evdi_calculate_recall(TRAIN_GT, top_rows['predicted_evidence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese were not used when initializing BertModel: ['pooler.dense.weight', 'pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModel\n",
        "import torch\n",
        "from torch import optim\n",
        "model=AutoModel.from_pretrained(\"IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese\")\n",
        "simcse_tok=AutoTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese\")\n",
        "\n",
        "TRAIN_GT = load_json(\"data/train_doc10sent5_all_ext.jsonl\")\n",
        "DEV_GT = load_json(\"data/dev_doc10sent5_all_ext.jsonl\")\n",
        "train_df = pd.DataFrame(TRAIN_GT)\n",
        "dev_df = pd.DataFrame(DEV_GT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "myModel(\n",
              "  (model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (transition_energy_net): Linear(in_features=768, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class ContrastiveModel(nn.Module):\n",
        "    def __init__(self,model=None):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "        self.transition_energy_net = nn.Linear(768, 768,bias=True)\n",
        "\n",
        "    def forward(self, input_ids,attention_mask):\n",
        "        output = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        energy = self.transition_energy_net(output['pooler_output'])\n",
        "\n",
        "        return energy\n",
        "\n",
        "simcse_model = ContrastiveModel(model)\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "simcse_model.to(device)\n",
        "NUM_EPOCHS=20\n",
        "optimizer = optim.AdamW(simcse_model.parameters(), lr=3e-5)\n",
        "num_training_steps = NUM_EPOCHS * len(TRAIN_GT)\n",
        "lr_scheduler = set_lr_scheduler(optimizer, num_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef1e1cbfbc014f00b2e6f60b13f1a973",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b67248c5cef840ae85bcef5da01bb11f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5512445095168375\n",
            "Recall: 0.7443142996583701\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "964075edcf0245188ff9cd91e61097a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5505124450951684\n",
            "Recall: 0.7438262567105908\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "tqdm.pandas()\n",
        "import opencc\n",
        "CONVERTER_T2S = opencc.OpenCC(\"t2s.json\")\n",
        "CONVERTER_S2T = opencc.OpenCC(\"s2t.json\")\n",
        "cos = torch.nn.CosineSimilarity(dim=1)\n",
        "result=[]\n",
        "step_cnt=0\n",
        "progress_bar = tqdm(train_df.iterrows())\n",
        "max_recall=0\n",
        "current_steps=0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    simcse_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    for _,row in train_df.iterrows():\n",
        "        # while 1:\n",
        "        page_score={}\n",
        "        if row[\"label\"] == \"NOT ENOUGH INFO\":\n",
        "            continue\n",
        "\n",
        "        gt_pages = [\n",
        "            [evidence[2],evidence[3]]\n",
        "            for evidence_set in row[\"evidence\"]\n",
        "            for evidence in evidence_set\n",
        "        ]\n",
        "        claim = row[\"claim\"]\n",
        "        claim_tok = simcse_tok(claim,return_tensors=\"pt\").to(device)\n",
        "        claim_output = simcse_model(\n",
        "            input_ids = claim_tok[\"input_ids\"],\n",
        "            attention_mask = claim_tok[\"attention_mask\"]\n",
        "        )\n",
        "        evd_list = row[\"predicted_evidence\"]\n",
        "        evd_content = []\n",
        "        simple_term_sentence=[]\n",
        "        pos_id=[]\n",
        "        neg_id=[]\n",
        "        for i,(evd,sent_id) in enumerate(evd_list):\n",
        "            if [evd,sent_id] in gt_pages:\n",
        "                pos_id.append(i)\n",
        "            else:\n",
        "                neg_id.append(i)\n",
        "            simple_term_sentence.append(simcse_tok(evd+\" : \"+mapping[evd][str(sent_id)])[\"input_ids\"])\n",
        "        if pos_id==[] or neg_id == []:\n",
        "            continue\n",
        "        combine_pad=[]\n",
        "        combine_max_len= max(map(len,simple_term_sentence))\n",
        "        for i in range(len(simple_term_sentence)):\n",
        "            if len(simple_term_sentence[i])<combine_max_len:\n",
        "                combine_pad.append(simple_term_sentence[i]+[simcse_tok.pad_token_id]*(combine_max_len-len(simple_term_sentence[i])))\n",
        "            else:\n",
        "                combine_pad.append(simple_term_sentence[i])\n",
        "        combine_pad = torch.tensor(combine_pad).to(device)\n",
        "        combine_attention_mask = (combine_pad!=simcse_tok.pad_token_id).to(device)\n",
        "        simple_output = simcse_model(\n",
        "            input_ids = combine_pad,\n",
        "            attention_mask = combine_attention_mask\n",
        "        )\n",
        "\n",
        "        # cos_sim = torch.matmul(claim_output,simple_output.T).squeeze(0)\n",
        "        cos_sim = cos(claim_output,simple_output)\n",
        "\n",
        "        pos_id = torch.tensor(pos_id)\n",
        "        neg_id = torch.tensor(neg_id)\n",
        "        pos_energy = cos_sim[pos_id]\n",
        "        neg_energy = cos_sim[neg_id]\n",
        "        rank_loss = torch.tensor([0.0], dtype=torch.float32,requires_grad=True,device=pos_energy.device)\n",
        "\n",
        "        for i in pos_energy:\n",
        "            neg_energy_seg = neg_energy[torch.where(neg_energy>i,True,False)]\n",
        "            if neg_energy_seg.size(0)==0:\n",
        "                continue\n",
        "            pos_energy_seg = i.expand_as(neg_energy_seg)\n",
        "\n",
        "            y = torch.ones_like(neg_energy_seg)  # 正樣本的標籤都是1\n",
        "            rank_loss_func = torch.nn.MarginRankingLoss(\n",
        "                math.exp(1/pos_id.size(0))\n",
        "            )\n",
        "            # print(neg_energy[:5])\n",
        "            rank_loss=rank_loss+rank_loss_func(pos_energy_seg, neg_energy_seg, y)\n",
        "        rank_loss = rank_loss/pos_id.size(0)\n",
        "        rank_loss = rank_loss/4\n",
        "        rank_loss.backward()\n",
        "        step_cnt+=1\n",
        "        if step_cnt==4:\n",
        "            step_cnt=0\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix(loss=rank_loss.item()*4)\n",
        "        current_steps+=1\n",
        "    # break\n",
        "    simcse_model.eval()\n",
        "    result=[]\n",
        "    for _,row in tqdm(dev_df.iterrows()):\n",
        "    \n",
        "        page_score={}\n",
        "\n",
        "        claim = row[\"claim\"]\n",
        "        claim_tok = simcse_tok(claim,return_tensors=\"pt\").to(device)\n",
        "        claim_output = simcse_model(\n",
        "            input_ids = claim_tok[\"input_ids\"],\n",
        "            attention_mask = claim_tok[\"attention_mask\"]\n",
        "        )\n",
        "        evd_list = row[\"predicted_evidence\"]\n",
        "        evd_content = []\n",
        "\n",
        "        for evd,sent_id in evd_list:\n",
        "            simple_tok = simcse_tok(evd+\" : \"+mapping[evd][str(sent_id)],return_tensors=\"pt\").to(device)\n",
        "            simple_output = simcse_model(\n",
        "                input_ids = simple_tok[\"input_ids\"],\n",
        "                attention_mask = simple_tok[\"attention_mask\"]\n",
        "            )\n",
        "            page_score[evd+\" \"+str(sent_id)] = cos(claim_output,simple_output).item()\n",
        "            # page_score[evd+\" \"+str(sent_id)] = torch.matmul(claim_output,simple_output.T).squeeze(0)\n",
        "        result.append([[key.split()[0],int(key.split()[1])] for key,_ in sorted(page_score.items(), key=lambda item: item[1],reverse=True)])\n",
        "    rerank_dev_df= dev_df.copy()\n",
        "    rerank_dev_df = rerank_dev_df.drop([\"predicted_evidence\"],axis=1)\n",
        "    rerank_dev_df.loc[:,\"predicted_evidence\"]=result\n",
        "    evdi_calculate_precision(DEV_GT, rerank_dev_df['predicted_evidence'])\n",
        "    recall = evdi_calculate_recall(DEV_GT, rerank_dev_df['predicted_evidence'])\n",
        "    if recall>max_recall:\n",
        "        max_recall=recall\n",
        "        save_checkpoint(simcse_model, \"checkpoints/rank_sent_retrieval\", current_steps,mark=f\"val_recall={recall:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:00, 12.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[6324, 6133, '北平_(消歧義)', 2], [6324, 6133, '北平_(五代)', 0], [6324, 6133, '北平_(五代)', 1], [6324, 6133, '北平_(五代)', 2], [6324, 6133, '北平_(五代)', 4], [6324, 6133, '北平_(五代)', 5]]]\n",
            "[[[11832, 10509, '抄襲', 3]]]\n",
            "[[[3346, 3510, '上座部佛教', 8], [3346, 3510, '根本分裂', 0]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [00:00, 13.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[9745, 8882, '李天命', 1]]]\n",
            "[[[13362, 11516, '陰陽', 0], [13362, 11516, '陰陽', 1], [13362, 11516, '陰陽', 4]]]\n",
            "[[[9184, 8408, '斯登衝鋒槍', 0], [9184, 8408, '斯登衝鋒槍', 1]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [00:00, 12.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[12496, None, None, None]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'int' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m _,row \u001b[39min\u001b[39;00m tqdm(top_rows\u001b[39m.\u001b[39miterrows()):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(row[\u001b[39m\"\u001b[39m\u001b[39mevidence\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m     gt_pages \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([\n\u001b[1;32m     10\u001b[0m         (evidence[\u001b[39m2\u001b[39m],evidence[\u001b[39m3\u001b[39m])\n\u001b[1;32m     11\u001b[0m         \u001b[39mfor\u001b[39;00m evidence_set \u001b[39min\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39mevidence\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m         \u001b[39mfor\u001b[39;00m evidence \u001b[39min\u001b[39;00m evidence_set\n\u001b[1;32m     13\u001b[0m     ])\n\u001b[1;32m     14\u001b[0m     \u001b[39m# print(gt_pages)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     page_score\u001b[39m=\u001b[39m{}\n",
            "Cell \u001b[0;32mIn[37], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m _,row \u001b[39min\u001b[39;00m tqdm(top_rows\u001b[39m.\u001b[39miterrows()):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(row[\u001b[39m\"\u001b[39m\u001b[39mevidence\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m     gt_pages \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([\n\u001b[0;32m---> 10\u001b[0m         (evidence[\u001b[39m2\u001b[39;49m],evidence[\u001b[39m3\u001b[39m])\n\u001b[1;32m     11\u001b[0m         \u001b[39mfor\u001b[39;00m evidence_set \u001b[39min\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39mevidence\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m         \u001b[39mfor\u001b[39;00m evidence \u001b[39min\u001b[39;00m evidence_set\n\u001b[1;32m     13\u001b[0m     ])\n\u001b[1;32m     14\u001b[0m     \u001b[39m# print(gt_pages)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     page_score\u001b[39m=\u001b[39m{}\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import opencc\n",
        "CONVERTER_T2S = opencc.OpenCC(\"t2s.json\")\n",
        "CONVERTER_S2T = opencc.OpenCC(\"s2t.json\")\n",
        "cos = torch.nn.CosineSimilarity(dim=1)\n",
        "result=[]\n",
        "simcse_model.eval()\n",
        "for _,row in tqdm(train_df.iterrows()):\n",
        "\n",
        "    page_score={}\n",
        "\n",
        "    claim = row[\"claim\"]\n",
        "    claim_tok = simcse_tok(claim,return_tensors=\"pt\").to(device)\n",
        "    claim_output = simcse_model(\n",
        "        input_ids = claim_tok[\"input_ids\"],\n",
        "        attention_mask = claim_tok[\"attention_mask\"]\n",
        "    )\n",
        "    evd_list = row[\"predicted_evidence\"]\n",
        "    evd_content = []\n",
        "\n",
        "    for evd,sent_id in evd_list:\n",
        "        simple_tok = simcse_tok(evd+\" : \"+mapping[evd][str(sent_id)],return_tensors=\"pt\").to(device)\n",
        "        simple_output = simcse_model(\n",
        "            input_ids = simple_tok[\"input_ids\"],\n",
        "            attention_mask = simple_tok[\"attention_mask\"]\n",
        "        )\n",
        "        page_score[evd+\" \"+str(sent_id)] = cos(claim_output,simple_output).item()\n",
        "\n",
        "    result.append([[key.split()[0],int(key.split()[1])] for key,_ in sorted(page_score.items(), key=lambda item: item[1],reverse=True)])\n",
        "rerank_train_top_rows= train_df.copy()\n",
        "rerank_train_top_rows = rerank_train_top_rows.drop([\"predicted_evidence\"],axis=1)\n",
        "rerank_train_top_rows.loc[:,\"predicted_evidence\"]=result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import opencc\n",
        "CONVERTER_T2S = opencc.OpenCC(\"t2s.json\")\n",
        "CONVERTER_S2T = opencc.OpenCC(\"s2t.json\")\n",
        "cos = torch.nn.CosineSimilarity(dim=1)\n",
        "result=[]\n",
        "simcse_model.eval()\n",
        "for _,row in tqdm(dev_df.iterrows()):\n",
        "\n",
        "    page_score={}\n",
        "\n",
        "    claim = row[\"claim\"]\n",
        "    claim_tok = simcse_tok(claim,return_tensors=\"pt\").to(device)\n",
        "    claim_output = simcse_model(\n",
        "        input_ids = claim_tok[\"input_ids\"],\n",
        "        attention_mask = claim_tok[\"attention_mask\"]\n",
        "    )\n",
        "    evd_list = row[\"predicted_evidence\"]\n",
        "    evd_content = []\n",
        "\n",
        "    for evd,sent_id in evd_list:\n",
        "        simple_tok = simcse_tok(evd+\" : \"+mapping[evd][str(sent_id)],return_tensors=\"pt\").to(device)\n",
        "        simple_output = simcse_model(\n",
        "            input_ids = simple_tok[\"input_ids\"],\n",
        "            attention_mask = simple_tok[\"attention_mask\"]\n",
        "        )\n",
        "        page_score[evd+\" \"+str(sent_id)] = cos(claim_output,simple_output).item()\n",
        "\n",
        "    result.append([[key.split()[0],int(key.split()[1])] for key,_ in sorted(page_score.items(), key=lambda item: item[1],reverse=True)])\n",
        "rerank_dev_top_rows = dev_df.copy()\n",
        "rerank_dev_top_rows = rerank_dev_top_rows.drop([\"predicted_evidence\"],axis=1)\n",
        "rerank_dev_top_rows.loc[:,\"predicted_evidence\"]=result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "evdi_calculate_precision(TRAIN_GT, rerank_train_top_rows['predicted_evidence'])\n",
        "evdi_calculate_recall(TRAIN_GT, rerank_train_top_rows['predicted_evidence'])\n",
        "print(\"=====\")\n",
        "evdi_calculate_precision(DEV_GT, rerank_dev_top_rows['predicted_evidence'])\n",
        "evdi_calculate_recall(DEV_GT, rerank_dev_top_rows['predicted_evidence'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4. Check on our test data\n",
        "(5 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lVFusJqjmex-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-bert-wwm-ext and are newly initialized: ['classifier.weight', 'ext_dense.bias', 'classifier.bias', 'ext_dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start predicting the test data\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d83581aedd2c44ab9ab825d66dbcaf41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9135 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.load_state_dict(torch.load(\"checkpoints/sent_retrieval/e10_bs32_2e-05_neg0.085_top5_all_ext/model.1899.pt\"))\n",
        "model.to(device)\n",
        "test_data = load_json(\"data/combine_test_doc10_all.jsonl\")\n",
        "\n",
        "test_evidences = pair_with_wiki_sentences_eval(\n",
        "    mapping,\n",
        "    pd.DataFrame(test_data),\n",
        "    is_testset=True,\n",
        ")\n",
        "test_set = SentRetrievalBERTDataset(test_evidences, tokenizer)\n",
        "test_dataloader = DataLoader(test_set, batch_size=256)\n",
        "\n",
        "print(\"Start predicting the test data\")\n",
        "probs = get_predicted_probs(model, test_dataloader, device)\n",
        "evaluate_retrieval(\n",
        "    probs=probs,\n",
        "    df_evidences=test_evidences,\n",
        "    ground_truths=test_data,\n",
        "    top_n=TOP_N,\n",
        "    cal_scores=False,\n",
        "    save_name=f\"combine_test_doc10sent{TOP_N}_ext.jsonl\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9038it [08:44, 17.24it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import opencc\n",
        "test_df = pd.DataFrame(load_json(\"data/combine_test_doc10sent5_ext.jsonl\"))\n",
        "CONVERTER_T2S = opencc.OpenCC(\"t2s.json\")\n",
        "CONVERTER_S2T = opencc.OpenCC(\"s2t.json\")\n",
        "cos = torch.nn.CosineSimilarity(dim=1)\n",
        "result=[]\n",
        "simcse_model.eval()\n",
        "for _,row in tqdm(test_df.iterrows()):\n",
        "\n",
        "    page_score={}\n",
        "\n",
        "    claim = row[\"claim\"]\n",
        "    claim_tok = simcse_tok(claim,return_tensors=\"pt\").to(device)\n",
        "    claim_output = simcse_model(\n",
        "        input_ids = claim_tok[\"input_ids\"],\n",
        "        attention_mask = claim_tok[\"attention_mask\"]\n",
        "    )\n",
        "    evd_list = row[\"predicted_evidence\"]\n",
        "    evd_content = []\n",
        "\n",
        "    for evd,sent_id in evd_list:\n",
        "        simple_tok = simcse_tok(evd+\" : \"+mapping[evd][str(sent_id)],return_tensors=\"pt\").to(device)\n",
        "        simple_output = simcse_model(\n",
        "            input_ids = simple_tok[\"input_ids\"],\n",
        "            attention_mask = simple_tok[\"attention_mask\"]\n",
        "        )\n",
        "        page_score[evd+\" \"+str(sent_id)] = cos(claim_output,simple_output).item()\n",
        "\n",
        "    result.append([[key.split()[0],int(key.split()[1])] for key,_ in sorted(page_score.items(), key=lambda item: item[1],reverse=True)])\n",
        "rerank_test_top_rows= test_df.copy()\n",
        "rerank_test_top_rows = rerank_test_top_rows.drop([\"predicted_evidence\"],axis=1)\n",
        "rerank_test_top_rows.loc[:,\"predicted_evidence\"]=result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test reranking results\n",
        "rerank_test_top_rows[[\"id\", \"claim\",\"predicted_pages\",\"predicted_evidence\"]].to_json(\n",
        "    \"data/combine_test_doc10sent5_reranlk_ext.jsonl\",\n",
        "    orient=\"records\",\n",
        "    lines=True,\n",
        "    force_ascii=False,\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lGzl8a5JteT7"
      },
      "source": [
        "notebook3\n",
        "## PART 3. Claim verification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tgA1vcUyzjlx"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandarallel import pandarallel\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.optim import AdamW,Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers import (\n",
        "    #AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_scheduler,\n",
        ")\n",
        "from modeling_bert import BertForSequenceClassification,BertForMaskedLM,BertForNextSentencePrediction\n",
        "from dataset import BERTDataset\n",
        "from utils import (\n",
        "    generate_evidence_to_wiki_pages_mapping,\n",
        "    jsonl_dir_to_df,\n",
        "    load_json,\n",
        "    load_model,\n",
        "    save_checkpoint,\n",
        "    set_lr_scheduler,\n",
        ")\n",
        "import opencc\n",
        "CONVERTER_T2S = opencc.OpenCC(\"t2s.json\")\n",
        "CONVERTER_S2T = opencc.OpenCC(\"s2t.json\")\n",
        "\n",
        "pandarallel.initialize(progress_bar=True, verbose=0, nb_workers=20)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "LABEL2ID: Dict[str, int] = {\n",
        "    \"supports\": 0,\n",
        "    \"refutes\": 1,\n",
        "    \"NOT ENOUGH INFO\": 2,\n",
        "}\n",
        "LABEL2TEXT: Dict[str, int] = {\n",
        "    \"supports\": \"對\",\n",
        "    \"refutes\": \"錯\",\n",
        "    \"NOT ENOUGH INFO\": \"無\",\n",
        "}\n",
        "TEXT2LABEL: Dict[str, int] = {\n",
        "    \"對\": \"supports\",\n",
        "    \"錯\": \"refutes\",\n",
        "    \"無\": \"NOT ENOUGH INFO\",\n",
        "}\n",
        "ID2LABEL: Dict[str, int] = {\n",
        "    \"0\": \"supports\",\n",
        "    \"1\": \"refutes\",\n",
        "    \"2\": \"NOT ENOUGH INFO\",\n",
        "}\n",
        "NUMBER2CHINESE: Dict[str, int] = {\n",
        "    0: \"零\",\n",
        "    1: \"一\",\n",
        "    2: \"二\",\n",
        "    3: \"三\",\n",
        "    4: \"四\",\n",
        "    5: \"五\"\n",
        "}\n",
        "ID2LABEL: Dict[int, str] = {v: k for k, v in LABEL2ID.items()}\n",
        "\n",
        "TRAIN_DATA = load_json(\"data/train_doc10sent5_all_rerank_ext.jsonl\")\n",
        "DEV_DATA = load_json(\"data/dev_doc10sent5_all_rerank_ext.jsonl\")\n",
        "\n",
        "TRAIN_PKL_FILE = Path(\"data/train_doc10sent5_all_rerank_ext.pkl\")\n",
        "DEV_PKL_FILE = Path(\"data/dev_doc10sent5_all_rerank_ext.pkl\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preload wiki database (same as part 2.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading and concatenating jsonl files in data/wiki-pages\n",
            "Generate parse mapping\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bbbfb900e97493580ae04c74916f4e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=59388), Label(value='0 / 59388')))…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transform to id to evidence_map mapping\n"
          ]
        }
      ],
      "source": [
        "wiki_pages = jsonl_dir_to_df(\"data/wiki-pages\")\n",
        "mapping = generate_evidence_to_wiki_pages_mapping(wiki_pages,)\n",
        "del wiki_pages"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper function"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AICUP dataset with top-k evidence sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AicupTopkEvidenceBERTDataset(BERTDataset):\n",
        "    \"\"\"AICUP dataset with top-k evidence sentences.\"\"\"\n",
        "\n",
        "    def __getitem__(\n",
        "        self,\n",
        "        idx: int,\n",
        "        **kwargs,\n",
        "    ) -> Tuple[Dict[str, torch.Tensor], int]:\n",
        "        item = self.data.iloc[idx]\n",
        "        claim = item[\"claim\"]\n",
        "        evidence = item[\"evidence_list\"]\n",
        "        pad = [\"[PAD]\"] * (self.topk - len(evidence))\n",
        "        evidence += pad\n",
        "\n",
        "        true_evidence=[]\n",
        "        for i,evd in enumerate(evidence):\n",
        "            if evd!='[PAD]':\n",
        "                true_evidence.append(evd)\n",
        "\n",
        "        # 錯誤 正確 沒有足夠證據\n",
        "        # 光學顯微鏡是以電磁學原理來將不可見或難見的微小物放大至肉眼可見的儀器。\n",
        "        # evid1 evid2\n",
        "        # 你主張 : 光學顯微鏡是以電磁學原理來將不可見或難見的微小物放大至肉眼可見的儀器。 因為證據有 : evid1  evid2 ... 所以我認為 [MASK]   \n",
        "        evidence_text=\"\"\n",
        "        # tmp_str=\"\"\n",
        "        for i,text in enumerate(true_evidence):\n",
        "            evidence_text+=str(i+1)+\". \"+text+\" \"\n",
        "\n",
        "        if evidence_text==\"\":\n",
        "            evidence_text='\"無\"。'\n",
        "\n",
        "        if \"label\" in item: \n",
        "            # concat_claim_evidence = \"我認為\"+'\"'+LABEL2TEXT[item[\"label\"]]+'\"'+\"，因為你認為 : \"+claim+\"，而證據有 : \"+evidence_text\n",
        "            concat_claim_evidence = \"我覺得\"+'\"'+LABEL2TEXT[item[\"label\"]]+'\"'+\"，因為你認為 : \"+claim+\"而證據有 : \"+evidence_text\n",
        "            # concat_claim_evidence = \"我認為\"+'\"'+LABEL2TEXT[item[\"label\"]]+'\"'+\"，因為結論為 : \"+claim+\"，而證明該結論有 : \"+evidence_text\n",
        "            # concat_claim_evidence = \"這讀起來\"+'\"'+LABEL2TEXT[item[\"label\"]]+'\"'+\": \"+claim+\"，\"+evidence_text\n",
        "            # concat_claim_evidence = '你主張\"'+claim+'\"，因證據有'+NUMBER2CHINESE[x]+'個: '+evidence_text+\"所以我覺得\"+'\"'+LABEL2TEXT[item[\"label\"]]+'\"'\n",
        "        else:\n",
        "            # concat_claim_evidence = \"我認為\"+'\"'+\"[MASK]\"+'\"'+\"，因為你認為 : \"+claim+\"，而證據有 : \"+evidence_text\n",
        "            concat_claim_evidence = \"我覺得\"+'\"'+\"[MASK]\"+'\"'+\"，因為你認為 : \"+claim+\"而證據有 : \"+evidence_text\n",
        "            # concat_claim_evidence = \"我認為\"+'\"'+\"[MASK]\"+'\"'+\"，因為結論為 : \"+claim+\"，而證明該結論有 : \"+evidence_text\n",
        "            # concat_claim_evidence = \"這讀起來\"+'\"'+\"[MASK]\"+'\"'+\"，結論: \"+claim+\" 原因: \"+evidence_text\n",
        "            # concat_claim_evidence = '你主張\"'+claim+'\"，因證據有'+NUMBER2CHINESE[x]+'個: '+evidence_text+\"所以我覺得\"+'\"'+\"[MASK]\"+'\"'\n",
        "\n",
        "        concat = self.tokenizer.encode(\n",
        "            concat_claim_evidence,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "        )\n",
        "        # prompt後\n",
        "        # maintain_label = (self.max_length-len(concat))\n",
        "        # concat = concat + [tokenizer.pad_token_id]*maintain_label\n",
        "        # concat = torch.tensor(concat)\n",
        "        # attention_mask = (concat!=tokenizer.pad_token_id)\n",
        "        # concat_ten={}\n",
        "        # if \"label\" in item: \n",
        "        #     label = torch.ones_like(concat).detach()*-100\n",
        "        #     maintain_label = -maintain_label-3\n",
        "        #     maintain = concat[maintain_label]\n",
        "        #     label[maintain_label] = maintain\n",
        "        #     concat[maintain_label]=tokenizer.mask_token_id\n",
        "        #     concat_ten[\"labels\"] = label.squeeze(0)\n",
        "        #     target = LABEL2ID[item[\"label\"]] if \"label\" in item else -1\n",
        "        #     concat_ten[\"target\"] = torch.tensor(target)\n",
        "        # concat_ten[\"input_ids\"] = concat\n",
        "        # concat_ten[\"attention_mask\"] = attention_mask\n",
        "        \n",
        "        # prompt前\n",
        "        concat = concat + [tokenizer.pad_token_id]*(self.max_length-len(concat))\n",
        "        concat = torch.tensor(concat)\n",
        "        attention_mask = (concat!=tokenizer.pad_token_id)\n",
        "        concat_ten={}\n",
        "        if \"label\" in item: \n",
        "            label = concat.detach().clone()\n",
        "            maintain = label[5]\n",
        "            label.masked_fill_(label!=maintain,-100)\n",
        "            concat[5]=tokenizer.mask_token_id\n",
        "            concat_ten[\"labels\"] = label.squeeze(0)\n",
        "            target = LABEL2ID[item[\"label\"]] if \"label\" in item else -1\n",
        "            concat_ten[\"target\"] = torch.tensor(target)\n",
        "        concat_ten[\"input_ids\"] = concat\n",
        "        concat_ten[\"attention_mask\"] = attention_mask\n",
        "        \n",
        "        return concat_ten"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_evaluation(model: torch.nn.Module, dataloader: DataLoader, device):\n",
        "    model.eval()\n",
        "\n",
        "    loss = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(dataloader)\n",
        "        for i,batch in enumerate(dataloader):\n",
        "            y_true.extend(batch[\"labels\"].tolist())\n",
        "\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss += outputs.loss.item()\n",
        "            logits = outputs.logits\n",
        "            y_pred.extend(torch.argmax(logits, dim=1).tolist())\n",
        "            progress_bar.set_postfix(loss=loss/(i+1),accuracy=accuracy_score(y_true, y_pred))\n",
        "            progress_bar.update(1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return {\"val_loss\": loss / len(dataloader), \"val_acc\": acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_evaluation_prompt(model: torch.nn.Module,tok, dataloader: DataLoader, device):\n",
        "    model.eval()\n",
        "\n",
        "    loss = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(dataloader)\n",
        "        for i,batch in enumerate(dataloader):\n",
        "            y_true.extend(batch[\"target\"].tolist())\n",
        "            batch = {k: v.to(device) for k, v in batch.items() if k!=\"target\"}\n",
        "            outputs = model(**batch)\n",
        "            mask_token_index = torch.where(batch[\"input_ids\"]==tok.mask_token_id,True,False)\n",
        "            mask_token_logits = outputs.logits[mask_token_index]\n",
        "            extract_label = tok.batch_encode_plus(list(TEXT2LABEL.keys()),add_special_tokens=False,return_tensors=\"pt\")['input_ids'].squeeze(1).unsqueeze(0)\n",
        "            extract_label_repeat = torch.repeat_interleave(extract_label,mask_token_logits.size(0),dim=0)\n",
        "            extract_label_output = torch.gather(mask_token_logits,1,extract_label_repeat.to(device))\n",
        "            max_label = torch.argmax(extract_label_output,dim=1).tolist()\n",
        "            y_pred.extend(max_label)\n",
        "            loss += outputs.loss.item()\n",
        "\n",
        "            progress_bar.set_postfix(loss=loss/(i+1),accuracy=accuracy_score(y_true, y_pred))\n",
        "            progress_bar.update(1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return {\"val_loss\": loss / len(dataloader), \"val_acc\": acc}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_predict(model: torch.nn.Module, test_dl: DataLoader, device) -> list:\n",
        "    model.eval()\n",
        "\n",
        "    preds = []\n",
        "    for batch in tqdm(test_dl,\n",
        "                      total=len(test_dl),\n",
        "                      leave=False,\n",
        "                      desc=\"Predicting\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        pred = model(**batch).logits\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "        preds.extend(pred.tolist())\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_predict_prompt(model: torch.nn.Module,tok, test_dl: DataLoader, device) -> list:\n",
        "    model.eval()\n",
        "\n",
        "    preds = []\n",
        "    for batch in tqdm(test_dl,\n",
        "                      total=len(test_dl),\n",
        "                      leave=False,\n",
        "                      desc=\"Predicting\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        mask_token_index = torch.where(batch[\"input_ids\"]==tok.mask_token_id,True,False)\n",
        "        mask_token_logits = outputs.logits[mask_token_index]\n",
        "        extract_label = tok.batch_encode_plus(list(TEXT2LABEL.keys()),add_special_tokens=False,return_tensors=\"pt\")['input_ids'].squeeze(1).unsqueeze(0)\n",
        "        extract_label_repeat = torch.repeat_interleave(extract_label,mask_token_logits.size(0),dim=0)\n",
        "        extract_label_output = torch.gather(mask_token_logits,1,extract_label_repeat.to(device))\n",
        "        max_label = torch.argmax(extract_label_output,dim=1).tolist()\n",
        "        preds.extend(max_label)\n",
        "    return preds"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def join_with_topk_evidence(\n",
        "    df: pd.DataFrame,\n",
        "    mapping: dict,\n",
        "    mode: str = \"train\",\n",
        "    topk: int = 5,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"join_with_topk_evidence join the dataset with topk evidence.\n",
        "\n",
        "    Note:\n",
        "        After extraction, the dataset will be like this:\n",
        "               id     label         claim                           evidence            evidence_list\n",
        "        0    4604  supports       高行健...     [[[3393, 3552, 高行健, 0], [...  [高行健 （ ）江西赣州出...\n",
        "        ..    ...       ...            ...                                ...                     ...\n",
        "        945  2095  supports       美國總...  [[[1879, 2032, 吉米·卡特, 16], [...  [卸任后 ， 卡特積極參與...\n",
        "        停各种战争及人質危機的斡旋工作 ， 反对美国小布什政府攻打伊拉克...\n",
        "\n",
        "        [946 rows x 5 columns]\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset with evidence.\n",
        "        wiki_pages (pd.DataFrame): The wiki pages dataframe\n",
        "        topk (int, optional): The topk evidence. Defaults to 5.\n",
        "        cache(Union[Path, str], optional): The cache file path. Defaults to None.\n",
        "            If cache is None, return the result directly.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The dataset with topk evidence_list.\n",
        "            The `evidence_list` column will be: List[str]\n",
        "    \"\"\"\n",
        "\n",
        "    # format evidence column to List[List[Tuple[str, str, str, str]]]\n",
        "    if \"evidence\" in df.columns:\n",
        "        df[\"evidence\"] = df[\"evidence\"].parallel_map(\n",
        "            lambda x: [[x]] if not isinstance(x[0], list) else [x]\n",
        "            if not isinstance(x[0][0], list) else x)\n",
        "    return df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1. Setup training environment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title  { display-mode: \"form\" }\n",
        "\n",
        "MODEL_NAME = \"hfl/chinese-bert-wwm-ext\"  #@param {type:\"string\"}\n",
        "TRAIN_BATCH_SIZE = 4  #@param {type:\"integer\"}\n",
        "TEST_BATCH_SIZE = 16  #@param {type:\"integer\"}\n",
        "SEED = 42  #@param {type:\"integer\"}\n",
        "LR = 7e-5  #@param {type:\"number\"}\n",
        "NUM_EPOCHS = 5  #@param {type:\"integer\"}\n",
        "MAX_SEQ_LEN = 300  #@param {type:\"integer\"}\n",
        "EVIDENCE_TOPK = 5  #@param {type:\"integer\"}\n",
        "VALIDATION_STEP = 500  #@param {type:\"integer\"}\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experiment Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_FILENAME = \"submission.jsonl\"\n",
        "\n",
        "EXP_DIR = f\"claim_verification/e{NUM_EPOCHS}_bs{TRAIN_BATCH_SIZE}_\" + f\"{LR}_top{EVIDENCE_TOPK}_ext_all_evi2_rerank5\"\n",
        "LOG_DIR = \"logs/\" + EXP_DIR\n",
        "CKPT_DIR = \"checkpoints/\" + EXP_DIR\n",
        "\n",
        "if not Path(LOG_DIR).exists():\n",
        "    Path(LOG_DIR).mkdir(parents=True)\n",
        "\n",
        "if not Path(CKPT_DIR).exists():\n",
        "    Path(CKPT_DIR).mkdir(parents=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2. Concat claim and evidences\n",
        "join topk evidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not TRAIN_PKL_FILE.exists():\n",
        "    train_df = join_with_topk_evidence(\n",
        "        pd.DataFrame(TRAIN_DATA),\n",
        "        mapping,\n",
        "        topk=EVIDENCE_TOPK,\n",
        "    )\n",
        "    train_df.to_pickle(TRAIN_PKL_FILE, protocol=5)\n",
        "else:\n",
        "    with open(TRAIN_PKL_FILE, \"rb\") as f:\n",
        "        train_df = pickle.load(f)\n",
        "\n",
        "if not DEV_PKL_FILE.exists():\n",
        "    dev_df = join_with_topk_evidence(\n",
        "        pd.DataFrame(DEV_DATA),\n",
        "        mapping,\n",
        "        mode=\"eval\",\n",
        "        topk=EVIDENCE_TOPK,\n",
        "    )\n",
        "    dev_df.to_pickle(DEV_PKL_FILE, protocol=5)\n",
        "else:\n",
        "    with open(DEV_PKL_FILE, \"rb\") as f:\n",
        "        dev_df = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "181b960117114d919d9e64ba2256cc97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "total_list=[]\n",
        "for i,row in tqdm(enumerate(train_df.iterrows())):\n",
        "    tmp=[]\n",
        "    for evi_id, evi_idx in row[1]['predicted_evidence'][:3]:\n",
        "\n",
        "        if evi_id == \"臺灣海峽危機#第二次臺灣海峽危機（1958）\":\n",
        "            continue\n",
        "        tmp.append(mapping[evi_id][str(evi_idx)])\n",
        "\n",
        "    total_list.append(tmp)\n",
        "#train_df = train_df.drop(\"evidence_list\",axis=1)\n",
        "train_df.loc[:, \"evidence_list\"] = total_list\n",
        "\n",
        "total_list=[]\n",
        "for i,row in tqdm(enumerate(dev_df.iterrows())):\n",
        "    tmp=[]\n",
        "    for evi_id, evi_idx in row[1]['predicted_evidence'][:3]:\n",
        "        if evi_id == \"臺灣海峽危機#第二次臺灣海峽危機（1958）\":\n",
        "            continue\n",
        "        tmp.append(mapping[evi_id][str(evi_idx)])\n",
        "    total_list.append(tmp)\n",
        "#dev_df = dev_df.drop(\"evidence_list\",axis=1)\n",
        "dev_df.loc[:, \"evidence_list\"] = total_list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3. Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prevent CUDA out of memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "O0rVk3990DlD"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_dataset = AicupTopkEvidenceBERTDataset(\n",
        "    train_df,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=MAX_SEQ_LEN,\n",
        ")\n",
        "val_dataset = AicupTopkEvidenceBERTDataset(\n",
        "    dev_df,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=MAX_SEQ_LEN,\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        ")\n",
        "eval_dataloader = DataLoader(val_dataset, batch_size=TEST_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可以不用執行 check train dataset時使用\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_dataset = AicupTopkEvidenceBERTDataset(\n",
        "    train_df,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=MAX_SEQ_LEN,\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CzMgs-Zs3sTN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at hfl/chinese-bert-wwm were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "#model = AutoModelForSequenceClassification.from_pretrained(\n",
        "model = BertForMaskedLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    # num_labels=len(LABEL2ID),\n",
        "    # type_vocab_size=7,\n",
        "    # ignore_mismatched_sizes=True\n",
        ")\n",
        "# model.load_state_dict(torch.load(\"checkpoints/claim_verification/e20_bs8_7e-05_top5_ext_all_evi3/val_acc=0.7146_model.7500_bs0.577.pt\"),strict=False)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "num_training_steps = NUM_EPOCHS * len(train_dataloader)\n",
        "lr_scheduler = set_lr_scheduler(optimizer, num_training_steps)\n",
        "\n",
        "writer = SummaryWriter(LOG_DIR)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training (30 mins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_aqMjEek3wmu"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ede34f66694d5881cc12b2c6e1932c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/11650 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ef39ce1a1e54a6fa4b8e6f99877b7c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500 val_loss: 0.8928324329118206\n",
            "500 val_acc: 0.6927038626609442\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb619a6bc09d496d9dfe588f1849b1d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000 val_loss: 0.8243427129640971\n",
            "1000 val_acc: 0.7072961373390558\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9247add4b9694e239ec2589f7701980a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500 val_loss: 0.8726550680521417\n",
            "1500 val_acc: 0.7030042918454935\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d87798925b5c4085b90d6b20078b6f1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000 val_loss: 0.8944448342878525\n",
            "2000 val_acc: 0.711587982832618\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8ffae5db2d54b27b318e1459d7b378e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2330 val_loss: 0.8293357702763113\n",
            "2330 val_acc: 0.7055793991416309\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a47badc03fd540dcb584e27c960cd661",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2500 val_loss: 0.9718346252833328\n",
            "2500 val_acc: 0.7107296137339055\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c81b3c8c9fb44dfa3d407286c5936f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000 val_loss: 1.0134965023153448\n",
            "3000 val_acc: 0.7188841201716738\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e4c26c8877347de86c6780fd0a1b9bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3500 val_loss: 0.9797987083662046\n",
            "3500 val_acc: 0.7133047210300429\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20e892c39fab49ef9bbc18b612daa768",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000 val_loss: 0.9656425836968096\n",
            "4000 val_acc: 0.7128755364806867\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cc8419102a54851a37a764ff36d283b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4500 val_loss: 1.0100778537253812\n",
            "4500 val_acc: 0.7064377682403433\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "164386e386dd478c8b48eba5555c05b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4660 val_loss: 0.8147847758580561\n",
            "4660 val_acc: 0.6922746781115879\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c604ef7b84064e92ab1976dee3021479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000 val_loss: 1.1248167616455522\n",
            "5000 val_acc: 0.7085836909871245\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6a678290d42431797dcd8f139b28676",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5500 val_loss: 0.9105253639082386\n",
            "5500 val_acc: 0.7103004291845494\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43763ffd5ecb4470adfdd7406cf86003",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6000 val_loss: 0.9633634368034258\n",
            "6000 val_acc: 0.6922746781115879\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05c51e7bcfbb41f38197c4b26f4bc78f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6500 val_loss: 0.9244728543578762\n",
            "6500 val_acc: 0.6690987124463519\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36cb10aa0ec74efe800b64ff0f360bf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6990 val_loss: 1.0046413462251833\n",
            "6990 val_acc: 0.6742489270386266\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "122bd68117bf42f196d1b7befc29c6ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7000 val_loss: 0.9053670584338985\n",
            "7000 val_acc: 0.6875536480686695\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8f235dcd42c4ffeb17ae202475aa7ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7500 val_loss: 1.0314801910968676\n",
            "7500 val_acc: 0.663519313304721\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac4d718f9b6c426095e03102b2e25813",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8000 val_loss: 1.1157817099600622\n",
            "8000 val_acc: 0.6639484978540773\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47ab2af244164478b0822f0d0722e9a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8500 val_loss: 0.912447160237456\n",
            "8500 val_acc: 0.6888412017167382\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d6614ba495417fb6b7b7f5f831dc90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9000 val_loss: 0.8141130118133271\n",
            "9000 val_acc: 0.7090128755364807\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f8d2cbc674a4957a9b32cc770ce7998",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9320 val_loss: 0.8948295680831556\n",
            "9320 val_acc: 0.7124463519313304\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "670a3b76e99a4513804db52f54c49351",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9500 val_loss: 1.2874118169284847\n",
            "9500 val_acc: 0.6828326180257511\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44dab4f09f6749a495b45975f8bc225b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/146 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000 val_loss: 0.8175377103767983\n",
            "10000 val_acc: 0.6909871244635193\n"
          ]
        }
      ],
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "current_steps = 0\n",
        "step_cnt=0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "\n",
        "    for i,batch in enumerate(train_dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items() if k!=\"target\"}\n",
        "        outputs = model(**batch)\n",
        "        # break\n",
        "        loss = outputs.loss\n",
        "        loss = loss/8\n",
        "        loss.backward()\n",
        "        step_cnt+=1\n",
        "        if step_cnt==8 or i==len(train_dataloader)-1:\n",
        "            step_cnt=0\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            lr_scheduler.step()\n",
        "        progress_bar.set_postfix(loss=loss.item()*8)\n",
        "        progress_bar.update(1)\n",
        "        writer.add_scalar(\"training_loss\", loss.item(), current_steps)\n",
        "\n",
        "\n",
        "        current_steps += 1\n",
        "\n",
        "        if current_steps%VALIDATION_STEP==0 or i==len(train_dataloader)-1:\n",
        "            # print(\"Start validation\")\n",
        "            # val_results = run_evaluation(model, eval_dataloader, device)\n",
        "            val_results = run_evaluation_prompt(model,tokenizer, eval_dataloader, device)\n",
        "\n",
        "            # # log each metric separately to TensorBoard\n",
        "            for metric_name, metric_value in val_results.items():\n",
        "                print(current_steps,f\"{metric_name}: {metric_value}\")\n",
        "                writer.add_scalar(f\"{metric_name}\", metric_value, current_steps)\n",
        "\n",
        "            save_checkpoint(\n",
        "                model,\n",
        "                CKPT_DIR,\n",
        "                current_steps,\n",
        "                mark=f\"val_acc={val_results['val_acc']:.4f}\",\n",
        "            )\n",
        "\n",
        "print(\"Finished training!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4. Make your submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zLkfuoAE49mz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting evidence_list for the eval mode ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59ff413a59e342379172fa5b85219aa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import json\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "TEST_DATA = load_json(\"data/combine_test_doc10sent5_rerank_ext.jsonl\")\n",
        "# TEST_PKL_FILE = Path(\"data/test_doc5sent5_imp.pkl\")\n",
        "\n",
        "# # if not TEST_PKL_FILE.exists():\n",
        "test_df = join_with_topk_evidence(\n",
        "    pd.DataFrame(TEST_DATA),\n",
        "    mapping,\n",
        "    mode=\"eval\",\n",
        "    topk=EVIDENCE_TOPK,\n",
        ")\n",
        "total_list=[]\n",
        "for i,row in tqdm(enumerate(test_df.iterrows())):\n",
        "\n",
        "    tmp=[]\n",
        "    for evi_id, evi_idx in row[1]['predicted_evidence'][:3]:\n",
        "\n",
        "        if evi_id == \"臺灣海峽危機#第二次臺灣海峽危機（1958）\":\n",
        "            continue\n",
        "        tmp.append(mapping[evi_id][str(evi_idx)])\n",
        "\n",
        "    # print(tmp)\n",
        "    total_list.append(tmp)\n",
        "    # break\n",
        "\n",
        "test_df.loc[:, \"evidence_list\"] = total_list\n",
        "\n",
        "test_dataset = AicupTopkEvidenceBERTDataset(\n",
        "    test_df,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=MAX_SEQ_LEN,\n",
        ")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqIjlht8yCMA"
      },
      "outputs": [],
      "source": [
        "# ckpt_name = \"val_acc=0.8174_model.5000.pt\"  #@param {type:\"string\"}\n",
        "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = BertForMaskedLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    # num_labels=len(LABEL2ID),\n",
        "    # type_vocab_size=7,\n",
        "    # ignore_mismatched_sizes=True\n",
        ")\n",
        "model.load_state_dict(torch.load(\"checkpoints/claim_verification/e5_bs4_0.002_top5_ext_all_evi2_rerank5/val_acc=0.7189_model.3000.pt\", map_location=\"cpu\"))\n",
        "model.to(device)\n",
        "# # predicted_label = run_predict(model, test_dataloader, device)\n",
        "predicted_label = run_predict_prompt(model,tokenizer, test_dataloader, device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Gl9I3ZWW4pHo"
      },
      "outputs": [],
      "source": [
        "predict_dataset = test_df.copy()\n",
        "predict_dataset[\"predicted_label\"] = list(map(ID2LABEL.get, predicted_label))\n",
        "for i,row in predict_dataset.iterrows():\n",
        "    if row['predicted_evidence'] == []:\n",
        "        predict_dataset.at[i,\"predicted_label\"] = \"NOT ENOUGH INFO\"\n",
        "        \n",
        "predict_dataset[[\"id\", \"predicted_label\", \"predicted_evidence\"]].to_json(\n",
        "    \"submission_combine_val_acc=0.7189_model.3000.jsonl\",\n",
        "    orient=\"records\",\n",
        "    lines=True,\n",
        "    force_ascii=False,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "10286f3c74912972f7d1fdceceee5be5b7c77248e5efe5afcbc6a71f24d230fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
